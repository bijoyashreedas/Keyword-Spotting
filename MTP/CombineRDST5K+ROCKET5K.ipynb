{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73d65b92-df59-40d6-99ae-b68fe57386fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "# Set seeds for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.backends.cudnn.is_available():\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32575bd1-eb57-4bab-8d14-a3d8af13f97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Base class template for Collection transformers.\n",
    "\n",
    "    class name: BaseCollectionTransformer\n",
    "\n",
    "Defining methods:\n",
    "    fitting         - fit(self, X, y=None)\n",
    "    transform       - transform(self, X, y=None)\n",
    "    fit&transform   - fit_transform(self, X, y=None)\n",
    "    updating        - update(self, X, y=None)\n",
    "\n",
    "Inherited inspection methods:\n",
    "    hyper-parameter inspection  - get_params()\n",
    "    fitted parameter inspection - get_fitted_params()\n",
    "\n",
    "State:\n",
    "    fitted model/strategy   - by convention, any attributes ending in \"_\"\n",
    "    fitted state flag       - is_fitted (property)\n",
    "    fitted state inspection - check_is_fitted()\n",
    "\"\"\"\n",
    "\n",
    "__maintainer__ = []\n",
    "__all__ = [\n",
    "    \"BaseCollectionTransformer\",\n",
    "]\n",
    "\n",
    "from abc import abstractmethod\n",
    "from typing import final\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from aeon.base import BaseCollectionEstimator\n",
    "from aeon.transformations.base import BaseTransformer\n",
    "\n",
    "\n",
    "class BaseCollectionTransformer(BaseCollectionEstimator, BaseTransformer):\n",
    "    \"\"\"Transformer base class for collections.\"\"\"\n",
    "\n",
    "    # tag values specific to CollectionTransformers\n",
    "    _tags = {\n",
    "        \"input_data_type\": \"Collection\",\n",
    "        \"output_data_type\": \"Collection\",\n",
    "        \"removes_unequal_length\": False,\n",
    "    }\n",
    "\n",
    "    @abstractmethod\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    @final\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"Fit transformer to X, optionally using y if supervised.\n",
    "\n",
    "        State change:\n",
    "            Changes state to \"fitted\".\n",
    "\n",
    "        Writes to self:\n",
    "        _is_fitted : flag is set to True.\n",
    "        model attributes (ending in \"_\") : dependent on estimator\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : np.ndarray or list\n",
    "            Input data, any number of channels, equal length series of shape ``(\n",
    "            n_cases, n_channels, n_timepoints)``\n",
    "            or list of numpy arrays (any number of channels, unequal length series)\n",
    "            of shape ``[n_cases]``, 2D np.array ``(n_channels, n_timepoints_i)``,\n",
    "            where ``n_timepoints_i`` is length of series ``i``. Other types are\n",
    "            allowed and converted into one of the above.\n",
    "\n",
    "            Different estimators have different capabilities to handle different\n",
    "            types of input. If `self.get_tag(\"capability:multivariate\")`` is False,\n",
    "            they cannot handle multivariate series. If ``self.get_tag(\n",
    "            \"capability:unequal_length\")`` is False, they cannot handle unequal\n",
    "            length input. In both situations, a ``ValueError`` is raised if X has a\n",
    "            characteristic that the estimator does not have the capability to handle.\n",
    "              Data to fit transform to, of valid collection type.\n",
    "        y : np.ndarray, default=None\n",
    "            1D np.array of float or str, of shape ``(n_cases)`` - class labels\n",
    "            (ground truth) for fitting indices corresponding to instance indices in X.\n",
    "            If None, no labels are used in fitting.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : a fitted instance of the estimator\n",
    "        \"\"\"\n",
    "        if self.get_tag(\"requires_y\"):\n",
    "            if y is None:\n",
    "                raise ValueError(\"Tag requires_y is true, but fit called with y=None\")\n",
    "        # skip the rest if fit_is_empty is True\n",
    "        if self.get_tag(\"fit_is_empty\"):\n",
    "            self.is_fitted = True\n",
    "            return self\n",
    "        self.reset()\n",
    "\n",
    "        # input checks and datatype conversion\n",
    "        X_inner = self._preprocess_collection(X)\n",
    "        y_inner = y\n",
    "        self._fit(X=X_inner, y=y_inner)\n",
    "\n",
    "        self.is_fitted = True\n",
    "\n",
    "        return self\n",
    "\n",
    "    @final\n",
    "    def transform(self, X, y=None):\n",
    "        \"\"\"Transform X and return a transformed version.\n",
    "\n",
    "        State required:\n",
    "            Requires state to be \"fitted\".\n",
    "\n",
    "        Accesses in self:\n",
    "        _is_fitted : must be True\n",
    "        fitted model attributes (ending in \"_\") : must be set, accessed by _transform\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : np.ndarray or list\n",
    "            Input data, any number of channels, equal length series of shape ``(\n",
    "            n_cases, n_channels, n_timepoints)``\n",
    "            or list of numpy arrays (any number of channels, unequal length series)\n",
    "            of shape ``[n_cases]``, 2D np.array ``(n_channels, n_timepoints_i)``,\n",
    "            where ``n_timepoints_i`` is length of series ``i``. Other types are\n",
    "            allowed and converted into one of the above.\n",
    "\n",
    "            Different estimators have different capabilities to handle different\n",
    "            types of input. If `self.get_tag(\"capability:multivariate\")`` is False,\n",
    "            they cannot handle multivariate series. If ``self.get_tag(\n",
    "            \"capability:unequal_length\")`` is False, they cannot handle unequal\n",
    "            length input. In both situations, a ``ValueError`` is raised if X has a\n",
    "            characteristic that the estimator does not have the capability to handle.\n",
    "              Data to fit transform to, of valid collection type.\n",
    "        y : np.ndarray, default=None\n",
    "            1D np.array of float or str, of shape ``(n_cases)`` - class labels\n",
    "            (ground truth) for fitting indices corresponding to instance indices in X.\n",
    "            If None, no labels are used in fitting.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        transformed version of X\n",
    "        \"\"\"\n",
    "        # check whether is fitted\n",
    "        self._check_is_fitted()\n",
    "\n",
    "        # input check and conversion for X/y\n",
    "        X_inner = self._preprocess_collection(X, store_metadata=False)\n",
    "        y_inner = y\n",
    "\n",
    "        if not self.get_tag(\"fit_is_empty\"):\n",
    "            self._check_shape(X)\n",
    "\n",
    "        Xt = self._transform(X=X_inner, y=y_inner)\n",
    "\n",
    "        return Xt\n",
    "\n",
    "    @final\n",
    "    def fit_transform(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Fit to data, then transform it.\n",
    "\n",
    "        Fits the transformer to X and y and returns a transformed version of X.\n",
    "\n",
    "        State change:\n",
    "            Changes state to \"fitted\".\n",
    "\n",
    "        Writes to self:\n",
    "        _is_fitted : flag is set to True.\n",
    "        model attributes (ending in \"_\") : dependent on estimator.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : np.ndarray or list\n",
    "            Input data, any number of channels, equal length series of shape ``(\n",
    "            n_cases, n_channels, n_timepoints)``\n",
    "            or list of numpy arrays (any number of channels, unequal length series)\n",
    "            of shape ``[n_cases]``, 2D np.array ``(n_channels, n_timepoints_i)``,\n",
    "            where ``n_timepoints_i`` is length of series ``i``. Other types are\n",
    "            allowed and converted into one of the above.\n",
    "\n",
    "            Different estimators have different capabilities to handle different\n",
    "            types of input. If `self.get_tag(\"capability:multivariate\")`` is False,\n",
    "            they cannot handle multivariate series. If ``self.get_tag(\n",
    "            \"capability:unequal_length\")`` is False, they cannot handle unequal\n",
    "            length input. In both situations, a ``ValueError`` is raised if X has a\n",
    "            characteristic that the estimator does not have the capability to handle.\n",
    "              Data to fit transform to, of valid collection type.\n",
    "        y : np.ndarray, default=None\n",
    "            1D np.array of float or str, of shape ``(n_cases)`` - class labels\n",
    "            (ground truth) for fitting indices corresponding to instance indices in X.\n",
    "            If None, no labels are used in fitting.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        transformed version of X\n",
    "        \"\"\"\n",
    "        # input checks and datatype conversion\n",
    "        self.reset()\n",
    "        X_inner = self._preprocess_collection(X)\n",
    "        y_inner = y\n",
    "        Xt = self._fit_transform(X=X_inner, y=y_inner)\n",
    "\n",
    "        self.is_fitted = True\n",
    "\n",
    "        return Xt\n",
    "\n",
    "    @final\n",
    "    def inverse_transform(self, X, y=None):\n",
    "        \"\"\"Inverse transform X and return an inverse transformed version.\n",
    "\n",
    "        Currently it is assumed that only transformers with tags\n",
    "             \"input_data_type\"=\"Series\", \"output_data_type\"=\"Series\",\n",
    "        can have an inverse_transform.\n",
    "\n",
    "        State required:\n",
    "             Requires state to be \"fitted\".\n",
    "\n",
    "        Accesses in self:\n",
    "         _is_fitted : must be True\n",
    "         fitted model attributes (ending in \"_\") : accessed by _inverse_transform\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : np.ndarray or list\n",
    "            Input data, any number of channels, equal length series of shape ``(\n",
    "            n_cases, n_channels, n_timepoints)``\n",
    "            or list of numpy arrays (any number of channels, unequal length series)\n",
    "            of shape ``[n_cases]``, 2D np.array ``(n_channels, n_timepoints_i)``,\n",
    "            where ``n_timepoints_i`` is length of series ``i``. Other types are\n",
    "            allowed and converted into one of the above.\n",
    "\n",
    "            Different estimators have different capabilities to handle different\n",
    "            types of input. If `self.get_tag(\"capability:multivariate\")`` is False,\n",
    "            they cannot handle multivariate series. If ``self.get_tag(\n",
    "            \"capability:unequal_length\")`` is False, they cannot handle unequal\n",
    "            length input. In both situations, a ``ValueError`` is raised if X has a\n",
    "            characteristic that the estimator does not have the capability to handle.\n",
    "              Data to fit transform to, of valid collection type.\n",
    "        y : np.ndarray, default=None\n",
    "            1D np.array of float or str, of shape ``(n_cases)`` - class labels\n",
    "            (ground truth) for fitting indices corresponding to instance indices in X.\n",
    "            If None, no labels are used in fitting.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        inverse transformed version of X\n",
    "            of the same type as X\n",
    "        \"\"\"\n",
    "        if not self.get_tag(\"capability:inverse_transform\"):\n",
    "            raise NotImplementedError(\n",
    "                f\"{type(self)} does not implement inverse_transform\"\n",
    "            )\n",
    "\n",
    "        # check whether is fitted\n",
    "        self._check_is_fitted()\n",
    "\n",
    "        # input check and conversion for X/y\n",
    "        X_inner = self._preprocess_collection(X, store_metadata=False)\n",
    "        y_inner = y\n",
    "\n",
    "        Xt = self._inverse_transform(X=X_inner, y=y_inner)\n",
    "\n",
    "        return Xt\n",
    "\n",
    "    def _fit(self, X, y=None):\n",
    "        \"\"\"Fit transformer to X and y.\n",
    "\n",
    "        private _fit containing the core logic, called from fit\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : Input data\n",
    "            Data to fit transform to, of valid collection type.\n",
    "        y : Target variable, default=None\n",
    "            Additional data, e.g., labels for transformation\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self: a fitted instance of the estimator\n",
    "\n",
    "        See extension_templates/transformer.py for implementation details.\n",
    "        \"\"\"\n",
    "        # default fit is \"no fitting happens\"\n",
    "        return self\n",
    "\n",
    "    @abstractmethod\n",
    "    def _transform(self, X, y=None):\n",
    "        \"\"\"Transform X and return a transformed version.\n",
    "\n",
    "        private _transform containing the core logic, called from transform\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : Input data\n",
    "            Data to fit transform to, of valid collection type.\n",
    "        y : Target variable, default=None\n",
    "            Additional data, e.g., labels for transformation\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        transformed version of X\n",
    "        \"\"\"\n",
    "\n",
    "    def _fit_transform(self, X, y=None):\n",
    "        \"\"\"Fit to data, then transform it.\n",
    "\n",
    "        Fits the transformer to X and y and returns a transformed version of X.\n",
    "\n",
    "        private _fit_transform containing the core logic, called from fit_transform.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : Input data\n",
    "            Data to fit transform to, of valid collection type.\n",
    "        y : Target variable, default=None\n",
    "            Additional data, e.g., labels for transformation.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        transformed version of X.\n",
    "        \"\"\"\n",
    "        # Non-optimized default implementation; override when a better\n",
    "        # method is possible for a given algorithm.\n",
    "        self._fit(X, y)\n",
    "        return self._transform(X, y)\n",
    "\n",
    "    def _inverse_transform(self, X, y=None):\n",
    "        \"\"\"Inverse transform X and return an inverse transformed version.\n",
    "\n",
    "        private _inverse_transform containing core logic, called from inverse_transform.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : Input data\n",
    "            Data to fit transform to, of valid collection type.\n",
    "        y : Target variable, default=None\n",
    "            Additional data, e.g., labels for transformation\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        inverse transformed version of X\n",
    "            of the same type as X.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\n",
    "            f\"{self.__class__.__name__} does not support inverse_transform\"\n",
    "        )\n",
    "\n",
    "    def _update(self, X, y=None):\n",
    "        \"\"\"Update transformer with X and y.\n",
    "\n",
    "        private _update containing the core logic, called from update\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : Input data\n",
    "            Data to fit transform to, of valid collection type.\n",
    "        y : Target variable, default=None\n",
    "            Additional data, e.g., labels for transformation\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self: a fitted instance of the estimator.\n",
    "        \"\"\"\n",
    "        # standard behaviour: no update takes place, new data is ignored\n",
    "        return self\n",
    "\n",
    "\n",
    "def _check_y(self, y, n_cases):\n",
    "    if y is None:\n",
    "        return None\n",
    "    # Check y valid input for collection transformations\n",
    "    if not isinstance(y, (pd.Series, np.ndarray)):\n",
    "        raise TypeError(\n",
    "            f\"y must be a np.array or a pd.Series, but found type: {type(y)}\"\n",
    "        )\n",
    "    if isinstance(y, np.ndarray) and y.ndim > 1:\n",
    "        raise TypeError(f\"y must be 1-dimensional, found {y.ndim} dimensions\")\n",
    "    # Check matching number of labels\n",
    "    n_labels = y.shape[0]\n",
    "    if n_cases != n_labels:\n",
    "        raise ValueError(\n",
    "            f\"Mismatch in number of cases. Number in X = {n_cases} nos in y = \"\n",
    "            f\"{n_labels}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "575eeb1f-86f9-403a-8d2b-49851c76d315",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Random Dilated Shapelet Transform (RDST) Classifier.\n",
    "\n",
    "A Random Dilated Shapelet Transform classifier pipeline that simply performs a random\n",
    "shapelet dilated transform and builds (by default) a ridge classifier on the output.\n",
    "\"\"\"\n",
    "\n",
    "__maintainer__ = [\"baraline\"]\n",
    "__all__ = [\"RDSTClassifier\"]\n",
    "\n",
    "from typing import Union\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from typing import Union, List, Dict\n",
    "from aeon.base._base import _clone_estimator\n",
    "from aeon.classification.base import BaseClassifier\n",
    "from aeon.transformations.collection.shapelet_based import (\n",
    "    RandomDilatedShapeletTransform,\n",
    ")\n",
    "\n",
    "\n",
    "class RDSTClassifier(BaseClassifier):\n",
    "    \"\"\"\n",
    "    A random dilated shapelet transform (RDST) classifier.\n",
    "\n",
    "    Implementation of the random dilated shapelet transform classifier pipeline\n",
    "    along the lines of [1]_, [2]_. Transforms the data using the\n",
    "    `RandomDilatedShapeletTransform` and then builds a `RidgeClassifierCV` classifier\n",
    "    with standard scaling.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    max_shapelets : int, default=10000\n",
    "        The maximum number of shapelets to keep for the final transformation.\n",
    "        A lower number of shapelets can be kept if alpha similarity has discarded the\n",
    "        whole dataset.\n",
    "    shapelet_lengths : array, default=None\n",
    "        The set of possible lengths for shapelets. Each shapelet length is uniformly\n",
    "        drawn from this set. If None, the shapelet length will be equal to\n",
    "        min(max(2,n_timepoints//2),11).\n",
    "    proba_normalization : float, default=0.8\n",
    "        This probability (between 0 and 1) indicates the chance of each shapelet to be\n",
    "        initialized such as it will use a z-normalized distance, inducing either scale\n",
    "        sensitivity or invariance. A value of 1 would mean that all shapelets will use\n",
    "        a z-normalized distance.\n",
    "    threshold_percentiles : array, default=None\n",
    "        The two perceniles used to select the threshold used to compute the Shapelet\n",
    "        Occurrence feature. If None, the 5th and the 10th percentiles (i.e. [5,10])\n",
    "        will be used.\n",
    "    alpha_similarity : float, default=0.5\n",
    "        The strength of the alpha similarity pruning. The higher the value, the fewer\n",
    "        common indexes with previously sampled shapelets are allowed when sampling a\n",
    "        new candidate with the same dilation parameter. It can cause the number of\n",
    "        sampled shapelets to be lower than max_shapelets if the whole search space has\n",
    "        been covered. The default is 0.5, and the maximum is 1. Values above it have\n",
    "        no effect for now.\n",
    "    use_prime_dilations : bool, default=False\n",
    "        If True, restricts the value of the shapelet dilation parameter to be prime\n",
    "        values. This can greatly speed-up the algorithm for long time series and/or\n",
    "        short shapelet lengths, possibly at the cost of some accuracy.\n",
    "    estimator : BaseEstimator or None, default=None\n",
    "        Base estimator for the ensemble, can be supplied a sklearn `BaseEstimator`. If\n",
    "        `None` a default `RidgeClassifierCV` classifier is used with standard scaling.\n",
    "    save_transformed_data : bool, default=False\n",
    "        If True, the transformed training dataset for all classifiers will be saved.\n",
    "    class_weight{“balanced”, “balanced_subsample”}, dict or list of dicts, default=None\n",
    "        Only applies if estimator is None, and the default is used.\n",
    "        From sklearn documentation:\n",
    "        If not given, all classes are supposed to have weight one.\n",
    "        The “balanced” mode uses the values of y to automatically adjust weights\n",
    "        inversely proportional to class frequencies in the input data as\n",
    "        n_samples / (n_classes * np.bincount(y))\n",
    "        The “balanced_subsample” mode is the same as “balanced” except that weights\n",
    "        are computed based on the bootstrap sample for every tree grown.\n",
    "        For multi-output, the weights of each column of y will be multiplied.\n",
    "        Note that these weights will be multiplied with sample_weight (passed through\n",
    "        the fit method) if sample_weight is specified.\n",
    "    n_jobs : int, default=1\n",
    "        The number of jobs to run in parallel for both ``fit`` and ``predict``.\n",
    "        `-1` means using all processors.\n",
    "    random_state : int, RandomState instance or None, default=None\n",
    "        If `int`, random_state is the seed used by the random number generator;\n",
    "        If `RandomState` instance, random_state is the random number generator;\n",
    "        If `None`, the random number generator is the `RandomState` instance used\n",
    "        by `np.random`.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    classes_ : list\n",
    "        The unique class labels in the training set.\n",
    "    n_classes_ : int\n",
    "        The number of unique classes in the training set.\n",
    "    transformed_data_ : list of shape (n_estimators) of ndarray\n",
    "        The transformed training dataset for all classifiers. Only saved when\n",
    "        ``save_transformed_data`` is `True`.\n",
    "\n",
    "    See Also\n",
    "    --------\n",
    "    RandomDilatedShapeletTransform : The randomly dilated shapelet transform.\n",
    "    RidgeClassifierCV : The default classifier used.\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] Antoine Guillaume et al. \"Random Dilated Shapelet Transform: A New Approach\n",
    "       for Time Series Shapelets\", Pattern Recognition and Artificial Intelligence.\n",
    "       ICPRAI 2022.\n",
    "    .. [2] Antoine Guillaume, \"Time series classification with shapelets: Application\n",
    "       to predictive maintenance on event logs\", PhD Thesis, University of Orléans,\n",
    "       2023.\n",
    "\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from aeon.classification.shapelet_based import RDSTClassifier\n",
    "    >>> from aeon.datasets import load_unit_test\n",
    "    >>> X_train, y_train = load_unit_test(split=\"train\")\n",
    "    >>> X_test, y_test = load_unit_test(split=\"test\")\n",
    "    >>> clf = RDSTClassifier(\n",
    "    ...     max_shapelets=10\n",
    "    ... )\n",
    "    >>> clf.fit(X_train, y_train)\n",
    "    RDSTClassifier(...)\n",
    "    >>> y_pred = clf.predict(X_test)\n",
    "    \"\"\"\n",
    "\n",
    "    _tags = {\n",
    "        \"capability:multivariate\": True,\n",
    "        \"capability:unequal_length\": True,\n",
    "        \"capability:multithreading\": True,\n",
    "        \"X_inner_type\": [\"np-list\", \"numpy3D\"],\n",
    "        \"algorithm_type\": \"shapelet\",\n",
    "    }\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        max_shapelets: int = 50000,\n",
    "        shapelet_lengths=None,\n",
    "        proba_normalization: float = 0.8,\n",
    "        threshold_percentiles=None,\n",
    "        alpha_similarity: float = 0.5,\n",
    "        use_prime_dilations: bool = False,\n",
    "        estimator=None,\n",
    "        save_transformed_data: bool = False,\n",
    "        class_weight=None,\n",
    "        n_jobs: int = 1,\n",
    "        random_state: Union[int, np.random.RandomState, None] = None,\n",
    "    ) -> None:\n",
    "        self.max_shapelets = max_shapelets\n",
    "        self.shapelet_lengths = shapelet_lengths\n",
    "        self.proba_normalization = proba_normalization\n",
    "        self.threshold_percentiles = threshold_percentiles\n",
    "        self.alpha_similarity = alpha_similarity\n",
    "        self.use_prime_dilations = use_prime_dilations\n",
    "        self.estimator = estimator\n",
    "        self.save_transformed_data = save_transformed_data\n",
    "        self.class_weight = class_weight\n",
    "        self.random_state = random_state\n",
    "        self.n_jobs = n_jobs\n",
    "\n",
    "        self.transformed_data_ = []\n",
    "\n",
    "        self._transformer = None\n",
    "        self._estimator = None\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "    def _fit(self, X, y):\n",
    "        \"\"\"Fit Classifier to training data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: np.ndarray shape (n_cases, n_channels, n_timepoints)\n",
    "            The training input samples.\n",
    "        y: array-like or list\n",
    "            The class labels for samples in X.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self :\n",
    "            Reference to self.\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        Changes state by creating a fitted model that updates attributes\n",
    "        ending in \"_\".\n",
    "        \"\"\"\n",
    "        self._transformer = RandomDilatedShapeletTransform(\n",
    "            max_shapelets=self.max_shapelets,\n",
    "            shapelet_lengths=self.shapelet_lengths,\n",
    "            proba_normalization=self.proba_normalization,\n",
    "            threshold_percentiles=self.threshold_percentiles,\n",
    "            alpha_similarity=self.alpha_similarity,\n",
    "            use_prime_dilations=self.use_prime_dilations,\n",
    "            n_jobs=self.n_jobs,\n",
    "            random_state=self.random_state,\n",
    "        )\n",
    "        if self.estimator is None:\n",
    "            self._estimator = make_pipeline(\n",
    "                StandardScaler(with_mean=True),\n",
    "                RidgeClassifierCV(\n",
    "                    alphas=np.logspace(-4, 4, 20),\n",
    "                    class_weight=self.class_weight,\n",
    "                ),\n",
    "            )\n",
    "        else:\n",
    "            self._estimator = _clone_estimator(self.estimator, self.random_state)\n",
    "            m = getattr(self._estimator, \"n_jobs\", None)\n",
    " \n",
    "            if m is not None:\n",
    "                self._estimator.n_jobs = self.n_jobs\n",
    "\n",
    "        X_t = self._transformer.fit_transform(X, y)\n",
    "\n",
    "        if self.save_transformed_data:\n",
    "            self.transformed_data_ = X_t\n",
    "\n",
    "        self._estimator.fit(X_t, y)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def _predict(self, X) -> np.ndarray:\n",
    "        \"\"\"Predicts labels for sequences in X.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: np.ndarray shape (n_cases, n_channels, n_timepoints)\n",
    "            The data to make predictions for.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        y : array-like, shape = [n_cases]\n",
    "            Predicted class labels.\n",
    "        \"\"\"\n",
    "        X_t = self._transformer.transform(X)\n",
    "\n",
    "        return self._estimator.predict(X_t)\n",
    "\n",
    "    def _predict_proba(self, X) -> np.ndarray:\n",
    "        \"\"\"Predicts label probabilities for sequences in X.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: np.ndarray shape (n_cases, n_channels, n_timepoints)\n",
    "            The data to predict probabilities for.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        y : array-like, shape = [n_cases, n_classes_]\n",
    "            Predicted probabilities using the ordering in classes_.\n",
    "        \"\"\"\n",
    "        X_t = self._transformer.transform(X)\n",
    "\n",
    "        m = getattr(self._estimator, \"predict_proba\", None)\n",
    "        if callable(m):\n",
    "            return self._estimator.predict_proba(X_t)\n",
    "        else:\n",
    "            dists = np.zeros((len(X), self.n_classes_))\n",
    "            preds = self._estimator.predict(X_t)\n",
    "            for i in range(0, len(X)):\n",
    "                dists[i, np.where(self.classes_ == preds[i])] = 1\n",
    "            return dists\n",
    "\n",
    "    def _get_test_params(\n",
    "        cls, parameter_set: str = \"default\"\n",
    "    ) -> Union[Dict, List[Dict]]:\n",
    "        \"\"\"Return testing parameter settings for the estimator.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        parameter_set : str, default=\"default\"\n",
    "            Name of the set of test parameters to return, for use in tests. If no\n",
    "            special parameters are defined for a value, will return `\"default\"` set.\n",
    "            For classifiers, a \"default\" set of parameters should be provided for\n",
    "            general testing, and a \"results_comparison\" set for comparing against\n",
    "            previously recorded results if the general set does not produce suitable\n",
    "            probabilities to compare against.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        params : dict or list of dict, default={}\n",
    "            Parameters to create testing instances of the class.\n",
    "            Each dict are parameters to construct an \"interesting\" test instance, i.e.,\n",
    "            `MyClass(**params)` or `MyClass(**params[i])` creates a valid test instance.\n",
    "        \"\"\"\n",
    "        return {\"max_shapelets\": 20}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eca9e9d4-cadd-4ab5-b7ab-b771a12a5299",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"RandOm Convolutional KErnel Transform (Rocket).\n",
    "\n",
    "Pipeline classifier using the ROCKET transformer and an sklearn classifier.\n",
    "\"\"\"\n",
    "\n",
    "__maintainer__ = []\n",
    "__all__ = [\"RocketClassifier\"]\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from aeon.transformations.collection import base\n",
    "from aeon.base._base import _clone_estimator\n",
    "from aeon.classification import BaseClassifier\n",
    "from aeon.transformations.collection.convolution_based import (\n",
    "    MiniRocket,\n",
    "    MultiRocket,\n",
    "    Rocket,\n",
    ")\n",
    "\n",
    "\n",
    "class RocketClassifier(BaseClassifier):\n",
    "    \"\"\"\n",
    "    Classifier wrapped for the Rocket transformer using RidgeClassifierCV.\n",
    "\n",
    "    This classifier simply transforms the input data using a Rocket [1,2,3]_\n",
    "    transformer, performs a Standard scaling and fits a sklearn classifier,\n",
    "    using the transformed data (default classifier is RidgeClassifierCV).\n",
    "\n",
    "    The classifier can be configured to use Rocket [1]_, MiniRocket [2]_ or\n",
    "    MultiRocket [3]_.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_kernels : int, default=10,000\n",
    "        The number of kernels for the Rocket transform.\n",
    "    rocket_transform : str, default=\"rocket\"\n",
    "        The type of Rocket transformer to use.\n",
    "        Valid inputs = [\"rocket\", \"minirocket\", \"multirocket\"].\n",
    "    max_dilations_per_kernel : int, default=32\n",
    "        MiniRocket and MultiRocket only. The maximum number of dilations per kernel.\n",
    "    n_features_per_kernel : int, default=4\n",
    "        MultiRocket only. The number of features per kernel.\n",
    "    estimator : sklearn compatible classifier or None, default=None\n",
    "        The estimator used. If None, a RidgeClassifierCV(alphas=np.logspace(-3, 3, 10))\n",
    "        is used.\n",
    "    class_weight{“balanced”, “balanced_subsample”}, dict or list of dicts, default=None\n",
    "        Only applies if estimator is None and the default is used.\n",
    "        From sklearn documentation:\n",
    "        If not given, all classes are supposed to have weight one.\n",
    "        The “balanced” mode uses the values of y to automatically adjust weights\n",
    "        inversely proportional to class frequencies in the input data as\n",
    "        n_samples / (n_classes * np.bincount(y))\n",
    "        The “balanced_subsample” mode is the same as “balanced” except that weights\n",
    "        are computed based on the bootstrap sample for every tree grown.\n",
    "        For multi-output, the weights of each column of y will be multiplied.\n",
    "        Note that these weights will be multiplied with sample_weight (passed through\n",
    "        the fit method) if sample_weight is specified.\n",
    "    n_jobs : int, default=1\n",
    "        The number of jobs to run in parallel for both `fit` and `predict`.\n",
    "        ``-1`` means using all processors.\n",
    "    random_state : int, RandomState instance or None, default=None\n",
    "        If `int`, random_state is the seed used by the random number generator;\n",
    "        If `RandomState` instance, random_state is the random number generator;\n",
    "        If `None`, the random number generator is the `RandomState` instance used\n",
    "        by `np.random`.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    n_classes_ : int\n",
    "        The number of classes.\n",
    "    classes_ : list\n",
    "        The classes labels.\n",
    "\n",
    "    See Also\n",
    "    --------\n",
    "    Rocket\n",
    "        Rocket transformers are in transformations/collection.\n",
    "    RocketRegressor\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] Dempster, A., Petitjean, F. and Webb, G.I., 2020. ROCKET: exceptionally fast\n",
    "        and accurate time series classification using random convolutional kernels.\n",
    "        Data Mining and Knowledge Discovery, 34(5), pp.1454-1495.\n",
    "    .. [2] Dempster, A., Schmidt, D.F. and Webb, G.I., 2021, August. Minirocket: A very\n",
    "        fast (almost) deterministic transform for time series classification. In\n",
    "        Proceedings of the 27th ACM SIGKDD conference on knowledge discovery & data\n",
    "        mining (pp. 248-257).\n",
    "    .. [3] Tan, C.W., Dempster, A., Bergmeir, C. and Webb, G.I., 2022. MultiRocket:\n",
    "        multiple pooling operators and transformations for fast and effective time\n",
    "        series classification. Data Mining and Knowledge Discovery, 36(5), pp.1623-1646.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from aeon.classification.convolution_based import RocketClassifier\n",
    "    >>> from aeon.datasets import load_unit_test\n",
    "    >>> X_train, y_train = load_unit_test(split=\"train\")\n",
    "    >>> X_test, y_test = load_unit_test(split=\"test\")\n",
    "    >>> clf = RocketClassifier(num_kernels=500)\n",
    "    >>> clf.fit(X_train, y_train)\n",
    "    RocketClassifier(...)\n",
    "    >>> y_pred = clf.predict(X_test)\n",
    "    \"\"\"\n",
    "\n",
    "    _tags = {\n",
    "        \"capability:multithreading\": True,\n",
    "        \"capability:multivariate\": True,\n",
    "        \"algorithm_type\": \"convolution\",\n",
    "    }\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_kernels=20000,\n",
    "        rocket_transform=\"rocket\",\n",
    "        max_dilations_per_kernel=32,\n",
    "        n_features_per_kernel=4,\n",
    "        estimator=None,\n",
    "        class_weight=None,\n",
    "        n_jobs=1,\n",
    "        random_state=None,\n",
    "    ):\n",
    "        self.num_kernels = num_kernels\n",
    "        self.rocket_transform = rocket_transform\n",
    "        self.max_dilations_per_kernel = max_dilations_per_kernel\n",
    "        self.n_features_per_kernel = n_features_per_kernel\n",
    "        self.estimator = estimator\n",
    "\n",
    "        self.class_weight = class_weight\n",
    "        self.n_jobs = n_jobs\n",
    "        self.random_state = random_state\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "    def _fit(self, X, y):\n",
    "        \"\"\"Fit Rocket variant to training data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 3D np.ndarray\n",
    "            The training data of shape = (n_cases, n_channels, n_timepoints).\n",
    "        y : 3D np.ndarray\n",
    "            The class labels, shape = (n_cases,).\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self :\n",
    "            Reference to self.\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        Changes state by creating a fitted model that updates attributes\n",
    "        ending in \"_\" and sets is_fitted flag to True.\n",
    "        \"\"\"\n",
    "        self.n_cases_, self.n_channels_, self.n_timepoints_ = X.shape\n",
    "\n",
    "        rocket_transform = self.rocket_transform.lower()\n",
    "        if rocket_transform == \"rocket\":\n",
    "            self._transformer = Rocket(\n",
    "                num_kernels=self.num_kernels,\n",
    "                n_jobs=self.n_jobs,\n",
    "                random_state=self.random_state,\n",
    "            )\n",
    "        elif rocket_transform == \"minirocket\":\n",
    "            self._transformer = MiniRocket(\n",
    "                num_kernels=self.num_kernels,\n",
    "                max_dilations_per_kernel=self.max_dilations_per_kernel,\n",
    "                n_jobs=self.n_jobs,\n",
    "                random_state=self.random_state,\n",
    "            )\n",
    "        elif rocket_transform == \"multirocket\":\n",
    "            self._transformer = MultiRocket(\n",
    "                num_kernels=self.num_kernels,\n",
    "                max_dilations_per_kernel=self.max_dilations_per_kernel,\n",
    "                n_features_per_kernel=self.n_features_per_kernel,\n",
    "                n_jobs=self.n_jobs,\n",
    "                random_state=self.random_state,\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid Rocket transformer: {self.rocket_transform}\")\n",
    "\n",
    "        self._scaler = StandardScaler(with_mean=False)\n",
    "        self._estimator = _clone_estimator(\n",
    "            (\n",
    "                RidgeClassifierCV(\n",
    "                    alphas=np.logspace(-3, 3, 10), class_weight=self.class_weight\n",
    "                )\n",
    "                if self.estimator is None\n",
    "                else self.estimator\n",
    "            ),\n",
    "            self.random_state,\n",
    "        )\n",
    "\n",
    "        self.pipeline_ = make_pipeline(\n",
    "            self._transformer,\n",
    "            self._scaler,\n",
    "            self._estimator,\n",
    "        )\n",
    "        self.pipeline_.fit(X, y)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def _predict(self, X) -> np.ndarray:\n",
    "        \"\"\"Predicts labels for sequences in X.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 3D np.ndarray of shape = (n_cases, n_channels, n_timepoints)\n",
    "            The data to make predictions for.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        y : array-like, shape = (n_cases,)\n",
    "            Predicted class labels.\n",
    "        \"\"\"\n",
    "        return self.pipeline_.predict(X)\n",
    "\n",
    "    def _predict_proba(self, X) -> np.ndarray:\n",
    "        \"\"\"Predicts labels probabilities for sequences in X.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 3D np.ndarray of shape = (n_cases, n_channels, n_timepoints)\n",
    "            The data to make predict probabilities for.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        y : array-like, shape = (n_cases, n_classes_)\n",
    "            Predicted probabilities using the ordering in classes_.\n",
    "        \"\"\"\n",
    "        m = getattr(self._estimator, \"predict_proba\", None)\n",
    "        if callable(m):\n",
    "            return self.pipeline_.predict_proba(X)\n",
    "        else:\n",
    "            dists = np.zeros((X.shape[0], self.n_classes_))\n",
    "            preds = self.pipeline_.predict(X)\n",
    "            for i in range(0, X.shape[0]):\n",
    "                dists[i, np.where(self.classes_ == preds[i])] = 1\n",
    "            return dists\n",
    "\n",
    "    @classmethod\n",
    "    def get_test_params(cls, parameter_set=\"default\"):\n",
    "        \"\"\"Return testing parameter settings for the estimator.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        parameter_set : str, default=\"default\"\n",
    "            Name of the set of test parameters to return, for use in tests. If no\n",
    "            special parameters are defined for a value, will return `\"default\"` set.\n",
    "            RocketClassifier provides the following special sets:\n",
    "                 \"results_comparison\" - used in some classifiers to compare against\n",
    "                    previously generated results where the default set of parameters\n",
    "                    cannot produce suitable probability estimates\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        params : dict or list of dict, default={}\n",
    "            Parameters to create testing instances of the class.\n",
    "            Each dict are parameters to construct an \"interesting\" test instance, i.e.,\n",
    "            `MyClass(**params)` or `MyClass(**params[i])` creates a valid test instance.\n",
    "            `create_test_instance` uses the first (or only) dictionary in `params`.\n",
    "        \"\"\"\n",
    "        if parameter_set == \"results_comparison\":\n",
    "            return {\"num_kernels\": 100}\n",
    "        else:\n",
    "            return {\"num_kernels\": 20}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90fafda3-1524-4520-ad8a-eff2b7ec4911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature array shape: (27692, 99, 13)\n",
      "Labels array shape: (27692,)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.fftpack import dct  # Import DCT from scipy\n",
    "import librosa  # Ensure librosa is imported for loading audio files\n",
    "\n",
    "# Custom Dataset Class\n",
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.X[idx], dtype=torch.float32), torch.tensor(self.y[idx], dtype=torch.long)\n",
    "\n",
    "def pre_emphasis(signal, alpha=0.97):\n",
    "    \"\"\"Apply pre-emphasis filter.\"\"\"\n",
    "    return np.append(signal[0], signal[1:] - alpha * signal[:-1])\n",
    "\n",
    "def framing(signal, frame_size, hop_size):\n",
    "    \"\"\"Split signal into overlapping frames.\"\"\"\n",
    "    num_frames = int(np.ceil(float(np.abs(len(signal) - frame_size)) / hop_size)) + 1\n",
    "    pad_signal_length = num_frames * hop_size + frame_size\n",
    "    z = np.zeros(pad_signal_length)\n",
    "    z[:len(signal)] = signal\n",
    "    \n",
    "    frames = np.lib.stride_tricks.as_strided(z,\n",
    "        shape=(num_frames, frame_size),\n",
    "        strides=(z.strides[0] * hop_size, z.strides[0])).copy()\n",
    "    \n",
    "    return frames\n",
    "\n",
    "def hamming_window(frame):\n",
    "    \"\"\"Apply Hamming window to a frame.\"\"\"\n",
    "    return np.hamming(len(frame)) * frame\n",
    "\n",
    "def mel_filter_bank(num_filters, fft_size, sample_rate, low_freq=0, high_freq=None):\n",
    "    \"\"\"Create a Mel filter bank.\"\"\"\n",
    "    if high_freq is None:\n",
    "        high_freq = sample_rate / 2\n",
    "    \n",
    "    # Convert frequency to Mel scale\n",
    "    low_mel = 2595 * np.log10(1 + low_freq / 700)\n",
    "    high_mel = 2595 * np.log10(1 + high_freq / 700)\n",
    "    \n",
    "    mel_points = np.linspace(low_mel, high_mel, num_filters + 2)\n",
    "    hz_points = 700 * (10**(mel_points / 2595) - 1)\n",
    "    \n",
    "    bin_points = np.floor((fft_size + 1) * hz_points / sample_rate).astype(int)\n",
    "    \n",
    "    filters = np.zeros((num_filters, int(np.floor(fft_size / 2 + 1))))\n",
    "    \n",
    "    for n in range(1, num_filters + 1):\n",
    "        filters[n - 1, bin_points[n - 1]:bin_points[n]] = \\\n",
    "            (np.arange(bin_points[n - 1], bin_points[n]) - bin_points[n - 1]) / (bin_points[n] - bin_points[n - 1])\n",
    "        filters[n - 1, bin_points[n]:bin_points[n + 1]] = \\\n",
    "            (bin_points[n + 1] - np.arange(bin_points[n], bin_points[n + 1])) / (bin_points[n + 1] - bin_points[n])\n",
    "    \n",
    "    return filters\n",
    "\n",
    "def compute_mfcc(signal, sample_rate=16000, n_mfcc=13, n_fft=400, hop_length=160):\n",
    "    \"\"\"Compute MFCC from scratch.\"\"\"\n",
    "    # Step 1: Pre-emphasis\n",
    "    emphasized_signal = pre_emphasis(signal)\n",
    "\n",
    "    # Step 2: Framing\n",
    "    frames = framing(emphasized_signal, n_fft, hop_length)\n",
    "\n",
    "    # Step 3: Apply Hamming window\n",
    "    windowed_frames = np.array([hamming_window(frame) for frame in frames])\n",
    "\n",
    "    # Step 4: FFT and Power Spectrum\n",
    "    mag_frames = np.abs(np.fft.rfft(windowed_frames, n=n_fft)) ** 2\n",
    "\n",
    "    # Step 5: Mel Filter Bank\n",
    "    mel_filters = mel_filter_bank(n_mfcc, n_fft, sample_rate)\n",
    "    \n",
    "    # Step 6: Apply Mel filter bank to power spectrum\n",
    "    mel_energies = np.dot(mag_frames, mel_filters.T)\n",
    "\n",
    "    # Step 7: Logarithm of Mel energies\n",
    "    log_mel_energies = np.log(mel_energies + np.finfo(float).eps)\n",
    "\n",
    "    # Step 8: Discrete Cosine Transform (DCT)\n",
    "    mfccs = dct(log_mel_energies, type=2, axis=1, norm='ortho')[:, :n_mfcc]\n",
    "\n",
    "    return mfccs\n",
    "\n",
    "def load_data_with_mfcc(directory, n_mfcc=13, n_fft=400, hop_size=160, target_length=16000):\n",
    "    \"\"\"Load data from a directory and extract MFCC features.\"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    labels = sorted(os.listdir(directory))\n",
    "    label_map = {label: idx for idx, label in enumerate(labels)}\n",
    "\n",
    "    for label in labels:\n",
    "        class_dir = os.path.join(directory, label)\n",
    "        if os.path.isdir(class_dir):\n",
    "            for file_name in os.listdir(class_dir):\n",
    "                if file_name.endswith('.wav'):\n",
    "                    file_path = os.path.join(class_dir, file_name)\n",
    "                    signal, rate = librosa.load(file_path, sr=None)  # Load audio to get its length\n",
    "                    \n",
    "                    # Check if the audio signal length is less than the target length (16000 samples)\n",
    "                    if len(signal) < target_length:\n",
    "                        # Pad the signal to 16000 samples if it's too short\n",
    "                        padding = target_length - len(signal)\n",
    "                        signal = np.pad(signal, (0, padding), 'constant')\n",
    "\n",
    "                    # Check if the audio length is greater than the target length (16000 samples)\n",
    "                    if len(signal) > target_length:\n",
    "                        # Truncate the signal to 16000 samples if it's too long\n",
    "                        signal = signal[:target_length]\n",
    "\n",
    "                    audio_length = len(signal)  # Length in samples\n",
    "                    mfcc = compute_mfcc(signal, sample_rate=rate, n_mfcc=n_mfcc, n_fft=n_fft, hop_length=hop_size)\n",
    "                    num_frames = mfcc.shape[1]\n",
    "\n",
    "                    # Check if the first window is less than 25 ms (400 samples)\n",
    "                    if num_frames > 0 and (num_frames * hop_size < 400):  \n",
    "                        print(f\"Stopping processing for {file_name}: first window is less than 30 ms.\")\n",
    "                        break\n",
    "                    \n",
    "                    X.append(mfcc)\n",
    "                    y.append(label_map[label])\n",
    "                    \n",
    "                    # Display number of frames and audio length for each sample\n",
    "                    #print(f\"File: {file_name}, Label: {label}, Audio Length: {audio_length} samples, Number of frames: {num_frames}\")\n",
    "\n",
    "                    # Print total number of windows for each file\n",
    "                    #print(f\"Total number of windows for {file_name}: {num_frames}\")\n",
    "\n",
    "                    # Print shape of the feature vector (MFCC matrix)\n",
    "                    #print(f\"MFCC feature vector shape for {file_name}: {mfcc.shape}\")\n",
    "\n",
    "            else:\n",
    "                continue  \n",
    "            break  \n",
    "\n",
    "    # Convert lists to numpy arrays\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    print(\"Feature array shape:\", X.shape)  \n",
    "    print(\"Labels array shape:\", y.shape)\n",
    "\n",
    "    return X, y, labels\n",
    "\n",
    "\n",
    "# Section 3: Data Loading and Preprocessing\n",
    "directory = \"C:/Users/WORKSTATIONS/Desktop/BijoyashreeDas/12KWS\"\n",
    "X, y, labels = load_data_with_mfcc(directory)\n",
    "\n",
    "# Reshape X for CNN input (add channel dimension if needed)\n",
    "if X.size > 0:\n",
    "   X = X[:, :, :]  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd0ce132-c5b8-40ca-bdc0-277aeb492326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape X for CNN input (swap dimensions 1 and 2)\n",
    "if X.size > 0:\n",
    "   X = X.transpose(0, 2, 1)  # Change shape from (23682, 50, 13) to (23682, 13, 50)\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# You can add your model training and evaluation code here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c46c71f-fb4c-4198-bc33-99eee6ecae6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27692, 13, 99)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d34d57d-16fb-4d6f-871f-53b7de6315f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = RocketClassifier(random_state=42,num_kernels=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14b98d1-85be-47ed-9542-0957d6bb0687",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1.fit(X_train,y_train)  # Fit the model\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1810aa1a-a4fd-465c-9e07-d27614d3ec97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(clf1, 'RocketClassifier_model.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072e3c02-727b-4095-bd6a-9f609ff115c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_transformed_rocket = clf1._transformer.transform(X_train)  # Transform the training data\n",
    "# Now `X_transformed` is your RDST feature matrix.\n",
    "# You can store it in a numpy matrix or save it to a file if needed.\n",
    "print(\"ROCKET Feature Matrix Shape:\", X_transformed_rocket.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431a82e2-d026-43ef-9706-4579fe000c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Save the feature matrix to a .npy file\n",
    "np.save('ROCKETFEATUREMATRIX.npy', X_transformed_rocket)\n",
    "\n",
    "# Confirm the file is saved\n",
    "print(\"rocket features saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5750c5f-9c95-4385-ab0e-fab48c274c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2 = RDSTClassifier(random_state=42,max_shapelets=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f752ca24-3134-4057-abb2-f4e1fdbba997",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2.fit(X_train,y_train)  # Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f34cd1-1ee1-4642-b233-340aa5b05886",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(clf2, 'RDSTClassifier_model.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e639159-4279-4f9f-9eab-283d54dcd100",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transformed_rdst = clf2._transformer.transform(X_train)\n",
    "\n",
    "# Now `X_transformed` is your RDST feature matrix.\n",
    "# You can store it in a numpy matrix or save it to a file if needed.\n",
    "print(\"RDST Feature Matrix Shape:\", X_transformed_rdst.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6011e5bb-022b-4e46-a576-bd7807134768",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Save the feature matrix to a .npy file\n",
    "np.save('RDSTFEATUREMATRIX.npy', X_transformed_rdst)\n",
    "\n",
    "# Confirm the file is saved\n",
    "print(\"rdst features saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77aa4864-98b5-4a67-8bbc-f1a8f4fd6055",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7f74ce-8728-4747-91b9-4e7d3490468f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3ca3ac1-bd13-4c21-99b8-8c6badc6d39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Load the trained model\n",
    "clf1 = joblib.load('RocketClassifier_model.pkl')\n",
    "\n",
    "# Now you can use clf1 to make predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e66ad20-82ed-4ac0-a1ed-a7627d3026f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2 = joblib.load('RDSTClassifier_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0c55ee0-4209-4b79-a121-6081a09b5e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROCKET feature matrix loaded successfully\n",
      "Shape: (22153, 200000)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load the feature matrix\n",
    "X_transformed_rocket = np.load('ROCKETFEATUREMATRIX.npy')\n",
    "\n",
    "# Confirm loading\n",
    "print(\"ROCKET feature matrix loaded successfully\")\n",
    "\n",
    "# Check the shape of the loaded matrix\n",
    "print(\"Shape:\", X_transformed_rocket.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be866e4b-037b-4db9-844d-964b70bc8083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RDST feature matrix loaded successfully\n",
      "Shape: (22153, 150000)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load the feature matrix\n",
    "X_transformed_rdst = np.load('RDSTFEATUREMATRIX.npy')\n",
    "\n",
    "# Confirm loading\n",
    "print(\"RDST feature matrix loaded successfully\")\n",
    "\n",
    "# Check the shape of the loaded matrix\n",
    "print(\"Shape:\", X_transformed_rdst.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28335c9-0b0c-4dff-9207-86ecdc7b20b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91e670d-d59d-48a5-bd8e-7165ae42596b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "846c199f-f540-4117-a56b-6093863a379c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Create a PCA object with n_components=20000\n",
    "pca1 = PCA(n_components=5000, random_state=42)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "01d01965-db7a-443a-87fa-0b504df101ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Create a PCA object with n_components=20000\n",
    "pca2 = PCA(n_components=5000, random_state=42)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdea0576-99c3-41c4-a9b3-e0fbfb214b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load the saved feature matrix\n",
    "X_transformed_rocket = np.load('ROCKETFEATUREMATRIX.npy')\n",
    "\n",
    "# Verify the shape of the loaded matrix\n",
    "print(X_transformed_rocket.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6ec8e2-0865-43ad-80bb-2e3f549f12b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load the saved feature matrix\n",
    "X_transformed_rdst = np.load('RDSTFEATUREMATRIX.npy')\n",
    "\n",
    "# Verify the shape of the loaded matrix\n",
    "print(X_transformed_rdst.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bc3856ce-5727-4bdc-9f41-5a782ed26d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform the data\n",
    "X_ROCKET_pca = pca1.fit_transform(X_transformed_rocket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "91cca896-478f-42a9-aa69-ca58f954c8bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22153, 5000)\n"
     ]
    }
   ],
   "source": [
    "print(X_ROCKET_pca.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8c55080a-3dbc-498e-85d1-7ca22d252c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_RDST_pca = pca2.fit_transform(X_transformed_rdst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ea91b56f-506b-44a4-b73b-1c258456efe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22153, 5000)\n"
     ]
    }
   ],
   "source": [
    "print(X_RDST_pca.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "963e9cd5-eb38-4ea5-8a8b-18367710af56",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_combined = np.concatenate((X_ROCKET_pca, X_RDST_pca), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c4af8503-157b-4135-a676-29f73a4bfded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22153, 10000)\n"
     ]
    }
   ],
   "source": [
    "print(X_combined.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "144674c6-9f71-47f6-bcaf-7911d17144e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RidgeClassifierCV(alphas=array([1.00000000e-03, 4.64158883e-03, 2.15443469e-02, 1.00000000e-01,\n",
       "       4.64158883e-01, 2.15443469e+00, 1.00000000e+01, 4.64158883e+01,\n",
       "       2.15443469e+02, 1.00000000e+03]))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RidgeClassifierCV</label><div class=\"sk-toggleable__content\"><pre>RidgeClassifierCV(alphas=array([1.00000000e-03, 4.64158883e-03, 2.15443469e-02, 1.00000000e-01,\n",
       "       4.64158883e-01, 2.15443469e+00, 1.00000000e+01, 4.64158883e+01,\n",
       "       2.15443469e+02, 1.00000000e+03]))</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RidgeClassifierCV(alphas=array([1.00000000e-03, 4.64158883e-03, 2.15443469e-02, 1.00000000e-01,\n",
       "       4.64158883e-01, 2.15443469e+00, 1.00000000e+01, 4.64158883e+01,\n",
       "       2.15443469e+02, 1.00000000e+03]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "import numpy as np\n",
    "\n",
    "# Define the classifier\n",
    "clf = RidgeClassifierCV(\n",
    "    alphas=np.logspace(-3, 3, 10),\n",
    "    class_weight=None  # Replace with self.class_weight if it's defined\n",
    ")\n",
    "\n",
    "# Fit the classifier\n",
    "clf.fit(X_combined, y_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2208a4fa-c13e-4d66-90d0-3c96d4093b0f",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "07be52e2-2faa-41ac-80c0-ca042210e1df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROCKET test Feature Matrix Shape: (5539, 200000)\n"
     ]
    }
   ],
   "source": [
    "X_test_transformed_rocket = clf1._transformer.transform(X_test)\n",
    "\n",
    "# Now `X_transformed` is your RDST feature matrix.\n",
    "# You can store it in a numpy matrix or save it to a file if needed.\n",
    "print(\"ROCKET test Feature Matrix Shape:\", X_test_transformed_rocket.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "10999fcc-7da7-4824-83af-9b0fcf8e6a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RDST test Feature Matrix Shape: (5539, 150000)\n"
     ]
    }
   ],
   "source": [
    "X_test_transformed_rdst = clf2._transformer.transform(X_test)\n",
    "\n",
    "# Now `X_transformed` is your RDST feature matrix.\n",
    "# You can store it in a numpy matrix or save it to a file if needed.\n",
    "print(\"RDST test Feature Matrix Shape:\", X_test_transformed_rdst.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "35f6704d-5817-4dfe-871c-2b48b826896a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_rocketcombined = np.concatenate((X_test_transformed_rocket, X_test_transformed_rocket), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ebaa17d8-d8d0-480f-b850-88119d0ae8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(X_rocketcombined.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "780da5fe-1929-40cd-84a7-3330f6fe315e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform the data\n",
    "X_test_ROCKET_pca = pca1.transform(X_test_transformed_rocket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fd2fca00-966f-44b4-9c13-f80ced2a85d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5539, 5000)\n"
     ]
    }
   ],
   "source": [
    "print(X_test_ROCKET_pca.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7ed6213b-40e0-4553-be2c-c4c7a92796ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_ROCKETreduced = X_test_ROCKET_pca[:5539, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f7022e54-4511-4acf-88fc-8345017b01f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(X_ROCKETreduced.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ccf8d09-3da5-408d-9e2b-236bff385f2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a42553d6-2ada-42c6-b8ef-1bbb82502f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_rdstcombined = np.concatenate((X_test_transformed_rdst, X_test_transformed_rdst), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7e2b4323-1bfd-47aa-9c4a-57d75a2d5a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform the data\n",
    "X_test_RDST_pca = pca2.transform(X_test_transformed_rdst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "423d1b68-6a93-497c-b676-7a7093318cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5539, 5000)\n"
     ]
    }
   ],
   "source": [
    "print(X_test_RDST_pca.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8db50c-dff5-4a0f-a8f4-22f509d25fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_RDSTreduced = X_test_RDST_pca[:5539, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a48dfe7-5dcc-4f55-8c99-128d802970b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(X_RDSTreduced.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a992f06-d061-441b-a075-dbe3f20b0763",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1aaee769-2376-4d5f-81e0-324ed59794ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_combined = np.concatenate((X_test_ROCKET_pca, X_test_RDST_pca), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a1c5faac-4d81-47b6-9a63-09e0e4a4a1f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5539, 10000)\n"
     ]
    }
   ],
   "source": [
    "print(X_test_combined.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6b59a327-7624-4edf-9d84-083a99e16094",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test_combined)  # Assuming you have a test set processed similarly\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2a5121d8-bee4-4743-9d07-07eb6e6222cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data: 0.9447553710055967\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Print the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy on test data:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "96e8d2fb-793a-4090-84bd-95c7d0c64485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision (macro): 0.9457195494009354\n",
      "Recall (macro): 0.9450087777207603\n",
      "F1 Score (macro): 0.945068677862199\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Calculate precision, recall, and f1 score for each class (macro average)\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "print(f\"Precision (macro): {precision}\")\n",
    "print(f\"Recall (macro): {recall}\")\n",
    "print(f\"F1 Score (macro): {f1}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5d7d37eb-7d89-4f03-adf2-888cc19933dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#confusion matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_curve, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "\n",
    "# Plot confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "df6b45c5-e157-4b23-8a0f-d84aa5c636f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        down       0.93      0.94      0.93       445\n",
      "          go       0.92      0.96      0.94       486\n",
      "        left       0.96      0.95      0.96       479\n",
      "          no       0.94      0.93      0.94       510\n",
      "         off       0.92      0.91      0.92       473\n",
      "          on       0.95      0.95      0.95       491\n",
      "       right       0.98      0.98      0.98       465\n",
      "     silence       0.99      1.00      0.99       383\n",
      "        stop       0.96      0.98      0.97       445\n",
      "     unknown       0.92      0.83      0.87       427\n",
      "          up       0.89      0.94      0.92       480\n",
      "         yes       0.98      0.98      0.98       455\n",
      "\n",
      "    accuracy                           0.94      5539\n",
      "   macro avg       0.95      0.95      0.95      5539\n",
      "weighted avg       0.94      0.94      0.94      5539\n",
      "\n",
      "Label mapping: {'down': 0, 'go': 1, 'left': 2, 'no': 3, 'off': 4, 'on': 5, 'right': 6, 'silence': 7, 'stop': 8, 'unknown': 9, 'up': 10, 'yes': 11}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score,classification_report\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred, target_names=labels))\n",
    "# Map for labels\n",
    "print(\"Label mapping:\", {idx: label for label, idx in enumerate(labels)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2021707a-c373-4ca1-9830-d7864d4de285",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e1d99b-6a75-4b65-8ffb-0468730b2307",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398f3412-12ba-472b-8893-d6565721485d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

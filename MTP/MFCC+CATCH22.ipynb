{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60e07b87-8f73-4cc4-8a84-928964fc2dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Catch22 Classifier.\n",
    "\n",
    "Pipeline classifier using the Catch22 transformer and an estimator.\n",
    "\"\"\"\n",
    "\n",
    "__maintainer__ = []\n",
    "__all__ = [\"Catch22Classifier\"]\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from aeon.base._base import _clone_estimator\n",
    "from aeon.classification import BaseClassifier\n",
    "from aeon.transformations.collection.feature_based import Catch22\n",
    "\n",
    "\n",
    "class Catch22Classifier(BaseClassifier):\n",
    "    \"\"\"\n",
    "    Canonical Time-series Characteristics (catch22) classifier.\n",
    "\n",
    "    This classifier simply transforms the input data using the Catch22 [1]_\n",
    "    transformer and builds a provided estimator using the transformed data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    features : int/str or List of int/str, default=\"all\"\n",
    "        The Catch22 features to extract by feature index, feature name as a str or as a\n",
    "        list of names or indices for multiple features. If \"all\", all features are\n",
    "        extracted. Valid features are as follows:\n",
    "            [\"DN_HistogramMode_5\", \"DN_HistogramMode_10\",\n",
    "            \"SB_BinaryStats_diff_longstretch0\", \"DN_OutlierInclude_p_001_mdrmd\",\n",
    "            \"DN_OutlierInclude_n_001_mdrmd\", \"CO_f1ecac\", \"CO_FirstMin_ac\",\n",
    "            \"SP_Summaries_welch_rect_area_5_1\", \"SP_Summaries_welch_rect_centroid\",\n",
    "            \"FC_LocalSimple_mean3_stderr\", \"CO_trev_1_num\", \"CO_HistogramAMI_even_2_5\",\n",
    "            \"IN_AutoMutualInfoStats_40_gaussian_fmmi\", \"MD_hrv_classic_pnn40\",\n",
    "            \"SB_BinaryStats_mean_longstretch1\", \"SB_MotifThree_quantile_hh\",\n",
    "            \"FC_LocalSimple_mean1_tauresrat\", \"CO_Embed2_Dist_tau_d_expfit_meandiff\",\n",
    "            \"SC_FluctAnal_2_dfa_50_1_2_logi_prop_r1\",\n",
    "            \"SC_FluctAnal_2_rsrangefit_50_1_logi_prop_r1\",\n",
    "            \"SB_TransitionMatrix_3ac_sumdiagcov\", \"PD_PeriodicityWang_th0_01\"]\n",
    "    catch24 : bool, default=True\n",
    "        Extract the mean and standard deviation as well as the 22 Catch22 features if\n",
    "        true. If a List of specific features to extract is provided, \"Mean\" and/or\n",
    "        \"StandardDeviation\" must be added to the List to extract these features.\n",
    "    outlier_norm : bool, optional, default=False\n",
    "        Normalise each series during the two outlier Catch22 features, which can take a\n",
    "        while to process for large values.\n",
    "    replace_nans : bool, default=True\n",
    "        Replace NaN or inf values from the Catch22 transform with 0.\n",
    "    use_pycatch22 : bool, default=False\n",
    "        Wraps the C based pycatch22 implementation for aeon.\n",
    "        (https://github.com/DynamicsAndNeuralSystems/pycatch22). This requires the\n",
    "        ``pycatch22`` package to be installed if True.\n",
    "    estimator : sklearn classifier, default=None\n",
    "        An sklearn estimator to be built using the transformed data.\n",
    "        Defaults to sklearn RandomForestClassifier(n_estimators=200).\n",
    "    random_state : int, RandomState instance or None, default=None\n",
    "        If `int`, random_state is the seed used by the random number generator;\n",
    "        If `RandomState` instance, random_state is the random number generator;\n",
    "        If `None`, the random number generator is the `RandomState` instance used\n",
    "        by `np.random`.\n",
    "    n_jobs : int, default=1\n",
    "        The number of jobs to run in parallel for both `fit` and `predict`.\n",
    "        ``-1`` means using all processors.\n",
    "    parallel_backend : str, ParallelBackendBase instance or None, default=None\n",
    "        Specify the parallelisation backend implementation in joblib for Catch22,\n",
    "        if None a 'prefer' value of \"threads\" is used by default.\n",
    "        Valid options are \"loky\", \"multiprocessing\", \"threading\" or a custom backend.\n",
    "        See the joblib Parallel documentation for more details.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    n_classes_ : int\n",
    "        Number of classes. Extracted from the data.\n",
    "    classes_ : ndarray of shape (n_classes_)\n",
    "        Holds the label for each class.\n",
    "    estimator_ : sklearn classifier\n",
    "        The fitted estimator.\n",
    "\n",
    "    See Also\n",
    "    --------\n",
    "    Catch22\n",
    "        Catch22 transformer in aeon/transformations/collection.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    Authors `catch22ForestClassifier <https://github.com/chlubba/sktime-catch22>`_.\n",
    "\n",
    "    For the Java version, see `tsml <https://github.com/uea-machine-learning/tsml/blob\n",
    "    /master/src/main/java/tsml/classifiers/hybrids/Catch22Classifier.java>`_.\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] Lubba, Carl H., et al. \"catch22: Canonical time-series characteristics.\"\n",
    "        Data Mining and Knowledge Discovery 33.6 (2019): 1821-1852.\n",
    "        https://link.springer.com/article/10.1007/s10618-019-00647-x\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from aeon.classification.feature_based import Catch22Classifier\n",
    "    >>> from sklearn.ensemble import RandomForestClassifier\n",
    "    >>> from aeon.testing.data_generation import make_example_3d_numpy\n",
    "    >>> X, y = make_example_3d_numpy(n_cases=10, n_channels=1, n_timepoints=12,\n",
    "    ...                              return_y=True, random_state=0)\n",
    "    >>> clf = Catch22Classifier(\n",
    "    ...     estimator=RandomForestClassifier(n_estimators=5),\n",
    "    ...     outlier_norm=True,\n",
    "    ...     random_state=0,\n",
    "    ... )\n",
    "    >>> clf.fit(X, y)\n",
    "    Catch22Classifier(...)\n",
    "    >>> clf.predict(X)\n",
    "    array([0, 1, 0, 1, 0, 0, 1, 1, 1, 0])\n",
    "    \"\"\"\n",
    "\n",
    "    _tags = {\n",
    "        \"X_inner_type\": [\"np-list\", \"numpy3D\"],\n",
    "        \"capability:multivariate\": True,\n",
    "        \"capability:unequal_length\": True,\n",
    "        \"capability:multithreading\": True,\n",
    "        \"algorithm_type\": \"feature\",\n",
    "    }\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        features=\"all\",\n",
    "        catch24=True,\n",
    "        outlier_norm=False,\n",
    "        replace_nans=True,\n",
    "        use_pycatch22=False,\n",
    "        estimator=None,\n",
    "        random_state=None,\n",
    "        n_jobs=1,\n",
    "        parallel_backend=None,\n",
    "    ):\n",
    "        self.features = features\n",
    "        self.catch24 = catch24\n",
    "        self.outlier_norm = outlier_norm\n",
    "        self.replace_nans = replace_nans\n",
    "        self.use_pycatch22 = use_pycatch22\n",
    "        self.estimator = estimator\n",
    "        self.random_state = random_state\n",
    "        self.n_jobs = n_jobs\n",
    "        self.parallel_backend = parallel_backend\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "    def _fit(self, X, y):\n",
    "        \"\"\"Fit Catch22Classifier to training data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 3D np.ndarray (any number of channels, equal length series)\n",
    "                of shape (n_cases, n_channels, n_timepoints)\n",
    "            or list of numpy arrays (any number of channels, unequal length series)\n",
    "                of shape [n_cases], 2D np.array (n_channels, n_timepoints_i), where\n",
    "                n_timepoints_i is length of series i\n",
    "        y : 1D np.array, of shape [n_cases] - class labels for fitting\n",
    "            indices correspond to instance indices in X\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self :\n",
    "            Reference to self.\n",
    "        \"\"\"\n",
    "        self._transformer = Catch22(\n",
    "            features=self.features,\n",
    "            catch24=self.catch24,\n",
    "            outlier_norm=self.outlier_norm,\n",
    "            replace_nans=self.replace_nans,\n",
    "            use_pycatch22=self.use_pycatch22,\n",
    "            n_jobs=self._n_jobs,\n",
    "            parallel_backend=self.parallel_backend,\n",
    "        )\n",
    "\n",
    "        self.estimator_ = _clone_estimator(\n",
    "            (\n",
    "                RandomForestClassifier(n_estimators=200)\n",
    "                if self.estimator is None\n",
    "                else self.estimator\n",
    "            ),\n",
    "            self.random_state,\n",
    "        )\n",
    "\n",
    "        m = getattr(self.estimator_, \"n_jobs\", None)\n",
    "        if m is not None:\n",
    "            self.estimator_.n_jobs = self._n_jobs\n",
    "\n",
    "        X_t = self._transformer.fit_transform(X, y)\n",
    "        self.estimator_.fit(X_t, y)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def _predict(self, X) -> np.ndarray:\n",
    "        \"\"\"Predicts labels for sequences in X.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 3D np.ndarray (any number of channels, equal length series)\n",
    "                of shape (n_cases, n_channels, n_timepoints)\n",
    "            or list of numpy arrays (any number of channels, unequal length series)\n",
    "                of shape [n_cases], 2D np.array (n_channels, n_timepoints_i), where\n",
    "                n_timepoints_i is length of series i\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        y : array-like, shape = [n_cases]\n",
    "            Predicted class labels.\n",
    "        \"\"\"\n",
    "        return self.estimator_.predict(self._transformer.transform(X))\n",
    "\n",
    "    def _predict_proba(self, X) -> np.ndarray:\n",
    "        \"\"\"Predicts labels probabilities for sequences in X.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 3D np.ndarray (any number of channels, equal length series)\n",
    "                of shape (n_cases, n_channels, n_timepoints)\n",
    "            or list of numpy arrays (any number of channels, unequal length series)\n",
    "                of shape [n_cases], 2D np.array (n_channels, n_timepoints_i), where\n",
    "                n_timepoints_i is length of series i\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        y : array-like, shape = [n_cases, n_classes_]\n",
    "            Predicted probabilities using the ordering in classes_.\n",
    "        \"\"\"\n",
    "        m = getattr(self.estimator_, \"predict_proba\", None)\n",
    "        if callable(m):\n",
    "            return self.estimator_.predict_proba(self._transformer.transform(X))\n",
    "        else:\n",
    "            dists = np.zeros((X.shape[0], self.n_classes_))\n",
    "            preds = self.estimator_.predict(self._transformer.transform(X))\n",
    "            for i in range(0, X.shape[0]):\n",
    "                dists[i, self._class_dictionary[preds[i]]] = 1\n",
    "            return dists\n",
    "\n",
    "    @classmethod\n",
    "    def _get_test_params(cls, parameter_set=\"default\"):\n",
    "        \"\"\"Return testing parameter settings for the estimator.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        parameter_set : str, default=\"default\"\n",
    "            Name of the set of test parameters to return, for use in tests. If no\n",
    "            special parameters are defined for a value, will return `\"default\"` set.\n",
    "            Catch22Classifier provides the following special sets:\n",
    "                 \"results_comparison\" - used in some classifiers to compare against\n",
    "                    previously generated results where the default set of parameters\n",
    "                    cannot produce suitable probability estimates\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        params : dict or list of dict, default={}\n",
    "            Parameters to create testing instances of the class.\n",
    "            Each dict are parameters to construct an \"interesting\" test instance, i.e.,\n",
    "            `MyClass(**params)` or `MyClass(**params[i])` creates a valid test instance.\n",
    "        \"\"\"\n",
    "        if parameter_set == \"results_comparison\":\n",
    "            return {\n",
    "                \"estimator\": RandomForestClassifier(n_estimators=10),\n",
    "                \"outlier_norm\": True,\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                \"estimator\": RandomForestClassifier(n_estimators=2),\n",
    "                \"features\": (\n",
    "                    \"Mean\",\n",
    "                    \"DN_HistogramMode_5\",\n",
    "                    \"SB_BinaryStats_mean_longstretch1\",\n",
    "                ),\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "785cca51-6597-46df-b258-368030718e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "# Set seeds for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.backends.cudnn.is_available():\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3fd77d-0f7d-4453-b61d-f131ce7207a8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "029f5e27-41d9-436d-aed0-8c6189a23d76",
   "metadata": {},
   "source": [
    "### Use this mfcc extraction(from scratch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af8296dc-0e4a-47d0-9872-2ebfdecf31bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature array shape: (27692, 99, 13)\n",
      "Labels array shape: (27692,)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.fftpack import dct  # Import DCT from scipy\n",
    "import librosa  # Ensure librosa is imported for loading audio files\n",
    "\n",
    "# Custom Dataset Class\n",
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.X[idx], dtype=torch.float32), torch.tensor(self.y[idx], dtype=torch.long)\n",
    "\n",
    "def pre_emphasis(signal, alpha=0.97):\n",
    "    \"\"\"Apply pre-emphasis filter.\"\"\"\n",
    "    return np.append(signal[0], signal[1:] - alpha * signal[:-1])\n",
    "\n",
    "def framing(signal, frame_size, hop_size):\n",
    "    \"\"\"Split signal into overlapping frames.\"\"\"\n",
    "    num_frames = int(np.ceil(float(np.abs(len(signal) - frame_size)) / hop_size)) + 1\n",
    "    pad_signal_length = num_frames * hop_size + frame_size\n",
    "    z = np.zeros(pad_signal_length)\n",
    "    z[:len(signal)] = signal\n",
    "    \n",
    "    frames = np.lib.stride_tricks.as_strided(z,\n",
    "        shape=(num_frames, frame_size),\n",
    "        strides=(z.strides[0] * hop_size, z.strides[0])).copy()\n",
    "    \n",
    "    return frames\n",
    "\n",
    "def hamming_window(frame):\n",
    "    \"\"\"Apply Hamming window to a frame.\"\"\"\n",
    "    return np.hamming(len(frame)) * frame\n",
    "\n",
    "def mel_filter_bank(num_filters, fft_size, sample_rate, low_freq=0, high_freq=None):\n",
    "    \"\"\"Create a Mel filter bank.\"\"\"\n",
    "    if high_freq is None:\n",
    "        high_freq = sample_rate / 2\n",
    "    \n",
    "    # Convert frequency to Mel scale\n",
    "    low_mel = 2595 * np.log10(1 + low_freq / 700)\n",
    "    high_mel = 2595 * np.log10(1 + high_freq / 700)\n",
    "    \n",
    "    mel_points = np.linspace(low_mel, high_mel, num_filters + 2)\n",
    "    hz_points = 700 * (10**(mel_points / 2595) - 1)\n",
    "    \n",
    "    bin_points = np.floor((fft_size + 1) * hz_points / sample_rate).astype(int)\n",
    "    \n",
    "    filters = np.zeros((num_filters, int(np.floor(fft_size / 2 + 1))))\n",
    "    \n",
    "    for n in range(1, num_filters + 1):\n",
    "        filters[n - 1, bin_points[n - 1]:bin_points[n]] = \\\n",
    "            (np.arange(bin_points[n - 1], bin_points[n]) - bin_points[n - 1]) / (bin_points[n] - bin_points[n - 1])\n",
    "        filters[n - 1, bin_points[n]:bin_points[n + 1]] = \\\n",
    "            (bin_points[n + 1] - np.arange(bin_points[n], bin_points[n + 1])) / (bin_points[n + 1] - bin_points[n])\n",
    "    \n",
    "    return filters\n",
    "\n",
    "def compute_mfcc(signal, sample_rate=16000, n_mfcc=13, n_fft=400, hop_length=160):\n",
    "    \"\"\"Compute MFCC from scratch.\"\"\"\n",
    "    # Step 1: Pre-emphasis\n",
    "    emphasized_signal = pre_emphasis(signal)\n",
    "\n",
    "    # Step 2: Framing\n",
    "    frames = framing(emphasized_signal, n_fft, hop_length)\n",
    "\n",
    "    # Step 3: Apply Hamming window\n",
    "    windowed_frames = np.array([hamming_window(frame) for frame in frames])\n",
    "\n",
    "    # Step 4: FFT and Power Spectrum\n",
    "    mag_frames = np.abs(np.fft.rfft(windowed_frames, n=n_fft)) ** 2\n",
    "\n",
    "    # Step 5: Mel Filter Bank\n",
    "    mel_filters = mel_filter_bank(n_mfcc, n_fft, sample_rate)\n",
    "    \n",
    "    # Step 6: Apply Mel filter bank to power spectrum\n",
    "    mel_energies = np.dot(mag_frames, mel_filters.T)\n",
    "\n",
    "    # Step 7: Logarithm of Mel energies\n",
    "    log_mel_energies = np.log(mel_energies + np.finfo(float).eps)\n",
    "\n",
    "    # Step 8: Discrete Cosine Transform (DCT)\n",
    "    mfccs = dct(log_mel_energies, type=2, axis=1, norm='ortho')[:, :n_mfcc]\n",
    "\n",
    "    return mfccs\n",
    "\n",
    "def load_data_with_mfcc(directory, n_mfcc=13, n_fft=400, hop_size=160, target_length=16000):\n",
    "    \"\"\"Load data from a directory and extract MFCC features.\"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    labels = sorted(os.listdir(directory))\n",
    "    label_map = {label: idx for idx, label in enumerate(labels)}\n",
    "\n",
    "    for label in labels:\n",
    "        class_dir = os.path.join(directory, label)\n",
    "        if os.path.isdir(class_dir):\n",
    "            for file_name in os.listdir(class_dir):\n",
    "                if file_name.endswith('.wav'):\n",
    "                    file_path = os.path.join(class_dir, file_name)\n",
    "                    signal, rate = librosa.load(file_path, sr=None)  # Load audio to get its length\n",
    "                    \n",
    "                    # Check if the audio signal length is less than the target length (16000 samples)\n",
    "                    if len(signal) < target_length:\n",
    "                        # Pad the signal to 16000 samples if it's too short\n",
    "                        padding = target_length - len(signal)\n",
    "                        signal = np.pad(signal, (0, padding), 'constant')\n",
    "\n",
    "                    # Check if the audio length is greater than the target length (16000 samples)\n",
    "                    if len(signal) > target_length:\n",
    "                        # Truncate the signal to 16000 samples if it's too long\n",
    "                        signal = signal[:target_length]\n",
    "\n",
    "                    audio_length = len(signal)  # Length in samples\n",
    "                    mfcc = compute_mfcc(signal, sample_rate=rate, n_mfcc=n_mfcc, n_fft=n_fft, hop_length=hop_size)\n",
    "                    num_frames = mfcc.shape[1]\n",
    "\n",
    "                    # Check if the first window is less than 25 ms (400 samples)\n",
    "                    if num_frames > 0 and (num_frames * hop_size < 400):  \n",
    "                        print(f\"Stopping processing for {file_name}: first window is less than 30 ms.\")\n",
    "                        break\n",
    "                    \n",
    "                    X.append(mfcc)\n",
    "                    y.append(label_map[label])\n",
    "                    \n",
    "                    # Display number of frames and audio length for each sample\n",
    "                    #print(f\"File: {file_name}, Label: {label}, Audio Length: {audio_length} samples, Number of frames: {num_frames}\")\n",
    "\n",
    "                    # Print total number of windows for each file\n",
    "                    #print(f\"Total number of windows for {file_name}: {num_frames}\")\n",
    "\n",
    "                    # Print shape of the feature vector (MFCC matrix)\n",
    "                    #print(f\"MFCC feature vector shape for {file_name}: {mfcc.shape}\")\n",
    "\n",
    "            else:\n",
    "                continue  \n",
    "            break  \n",
    "\n",
    "    # Convert lists to numpy arrays\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    print(\"Feature array shape:\", X.shape)  \n",
    "    print(\"Labels array shape:\", y.shape)\n",
    "\n",
    "    return X, y, labels\n",
    "\n",
    "\n",
    "# Section 3: Data Loading and Preprocessing\n",
    "directory = \"C:/Users/WORKSTATIONS/Desktop/BijoyashreeDas/12KWS\"\n",
    "X, y, labels = load_data_with_mfcc(directory)\n",
    "\n",
    "# Reshape X for CNN input (add channel dimension if needed)\n",
    "if X.size > 0:\n",
    "   X = X[:, :, :]  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7208e75-8254-4cec-a327-dac61954bc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape X for CNN input (swap dimensions 1 and 2)\n",
    "if X.size > 0:\n",
    "   X = X.transpose(0, 2, 1)  # Change shape from (23682, 50, 13) to (23682, 13, 50)\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# You can add your model training and evaluation code here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41ae1395-55d6-4729-8226-33b8b9b64516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27692, 13, 99)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e6a176f-d37a-42ea-92ba-eb827786cead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22153, 13, 99)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a0f55a3-b114-48a0-9e1b-0024076d3882",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Catch22Classifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49cba261-582a-4b4f-b4bd-004c08d24b02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Catch22Classifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Catch22Classifier</label><div class=\"sk-toggleable__content\"><pre>Catch22Classifier(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "Catch22Classifier(random_state=42)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the classifier on the training data\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79050deb-a191-471d-a83e-8b1760179385",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Catch22Classifier' object has no attribute 'pipeline_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22344\\774889698.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mparam\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpipeline_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Counting the number of parameters (coef_ and intercept_)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mn_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mparam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintercept_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Number of parameters: {n_params}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Catch22Classifier' object has no attribute 'pipeline_'"
     ]
    }
   ],
   "source": [
    "param = clf.pipeline_[-1]  \n",
    "\n",
    "# Counting the number of parameters (coef_ and intercept_)\n",
    "n_params = param.coef_.size + param.intercept_.size\n",
    "print(f\"Number of parameters: {n_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbd12230-31f0-48c5-a927-8df55447d54f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data: 0.7257627730637299\n"
     ]
    }
   ],
   "source": [
    "# Predict on the test set\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score,accuracy_score\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Print the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy on test data:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "382dfc69-1415-4ec6-8fea-e11a20167413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision (macro): 0.7346867186064546\n",
      "Recall (macro): 0.7278202376175597\n",
      "F1 Score (macro): 0.7181761693782801\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Calculate precision, recall, and f1 score for each class (macro average)\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "print(f\"Precision (macro): {precision}\")\n",
    "print(f\"Recall (macro): {recall}\")\n",
    "print(f\"F1 Score (macro): {f1}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b29de87-10ed-4bc8-b7d7-33bb02feaf71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_curve, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Plot confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "\n",
    "# Save the plot as an image (e.g., PNG file)\n",
    "plt.savefig(\"confusion_matrix_rocket120K.png\")  # Change the file name and extension as needed\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d9425f-d946-4c4c-904c-36dc9358a226",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score,classification_report\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred, target_names=labels))\n",
    "# Map for labels\n",
    "print(\"Label mapping:\", {idx: label for label, idx in enumerate(labels)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c472e9c7-ec0f-40ba-a59b-b255519101f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "# Get classification report\n",
    "report = classification_report(y_test, y_pred, target_names=labels)\n",
    "\n",
    "# Print the classification report to console\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "# Save the classification report to a text file\n",
    "with open(\"classification_report_ROCKET120K.txt\", \"w\") as f:\n",
    "    f.write(\"Classification Report:\\n\")\n",
    "    f.write(report)\n",
    "\n",
    "# Map for labels\n",
    "print(\"Label mapping:\", {idx: label for label, idx in enumerate(labels)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6203c452-66d9-4bee-8b65-0e09ec06dbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Get classification report\n",
    "report = classification_report(y_test, y_pred, target_names=labels)\n",
    "\n",
    "# Print the classification report to the console\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "# Save the classification report to a text file\n",
    "with open(\"classification_report_ROCKET120K.txt\", \"w\") as f:\n",
    "    f.write(\"Classification Report:\\n\")\n",
    "    f.write(report)\n",
    "\n",
    "# Save classification report as an image\n",
    "# Create a figure and axes\n",
    "fig, ax = plt.subplots(figsize=(10, 6))  # Adjust size as needed\n",
    "ax.axis('off')  # Turn off the axis\n",
    "\n",
    "# Create the text image\n",
    "ax.text(0.5, 0.5, report, fontsize=12, ha='center', va='center', fontweight='bold', family='monospace')\n",
    "\n",
    "# Save the image\n",
    "plt.savefig(\"classification_report_image_ROCKET120K.png\", bbox_inches='tight', dpi=300)\n",
    "\n",
    "# Map for labels\n",
    "print(\"Label mapping:\", {idx: label for label, idx in enumerate(labels)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b08536b-2125-4097-bf81-4205d9313656",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a3f928-6e6d-479f-b84e-2c02b5dab679",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49ed00b-eb2e-45eb-a38d-d382ab94f0b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b7c714-7cff-4f5b-a5a6-3f15ebe0a111",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127a24b3-03f1-4953-bde4-83b6aa94979c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411d3aa6-9887-495b-8b8f-dd893995e342",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Example: Define y_test and y_pred\n",
    "# Replace these with your actual labels\n",
    "# y_test = [0, 1, 2, 0, 1, 2]  # True labels\n",
    "# y_pred = [0, 2, 1, 0, 0, 1]  # Predicted labels\n",
    "\n",
    "# Get the unique classes and binarize labels\n",
    "classes = np.unique(y_test)\n",
    "y_test_bin = label_binarize(y_test, classes=classes)\n",
    "y_pred_bin = label_binarize(y_pred, classes=classes)\n",
    "\n",
    "n_classes = y_test_bin.shape[1]\n",
    "\n",
    "# Plot Precision-Recall Curve\n",
    "plt.figure(figsize=(10, 7))\n",
    "for i in range(n_classes):\n",
    "    precision, recall, _ = precision_recall_curve(y_test_bin[:, i], y_pred_bin[:, i])\n",
    "    plt.plot(recall, precision, lw=2, label=f'Class {classes[i]}')\n",
    "\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision-Recall Curve\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7d907b-03cf-4436-a25c-f0fe74871df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a243151-0fb9-4ae2-b834-1d6edb4b1514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predicted probabilities using the predict_proba() method\n",
    "y_pred_prob = clf.predict_proba(X_test)\n",
    "\n",
    "# Binarize the true labels\n",
    "classes = np.unique(y_test)\n",
    "y_test_bin = label_binarize(y_test, classes=classes)\n",
    "\n",
    "n_classes = 12\n",
    "\n",
    "# Plot Precision-Recall Curve\n",
    "plt.figure(figsize=(10, 7))\n",
    "for i in range(n_classes):\n",
    "    # Get precision and recall for each class using the predicted probabilities\n",
    "    precision, recall, _ = precision_recall_curve(y_test_bin[:, i], y_pred_prob[:, i])\n",
    "    plt.plot(recall, precision, lw=2, label=f'Class {classes[i]}')\n",
    "\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision-Recall Curve\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58f6972-9031-474d-bceb-4e6c92635c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77d4f3f-1465-48cf-a0d7-c666db539bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Plot ROC Curve\n",
    "plt.figure(figsize=(10, 7))\n",
    "for i in range(n_classes):\n",
    "    # Get ROC curve metrics for each class\n",
    "    fpr, tpr, _ = roc_curve(y_test_bin[:, i], y_pred_prob[:, i])\n",
    "    roc_auc = auc(fpr, tpr)  # Compute AUC for each class\n",
    "    plt.plot(fpr, tpr, lw=2, label=f'Class {classes[i]} (AUC = {roc_auc:.2f})')\n",
    "\n",
    "# Plot the diagonal line for random classifier (AUC = 0.5)\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "\n",
    "# Plot details\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Receiver Operating Characteristic (ROC) Curve\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b19283-20dc-4142-85c1-6314e6a05aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Print the classification report\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9c6399-1975-4bcc-ba03-283b8b63014c",
   "metadata": {},
   "outputs": [],
   "source": [
    "99//2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd33f11-1d7c-4ab6-8708-54ecf09fb62b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

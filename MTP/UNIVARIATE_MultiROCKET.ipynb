{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Set a global random seed\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"RandOm Convolutional KErnel Transform (Rocket).\n",
    "\n",
    "Pipeline classifier using the ROCKET transformer and an sklearn classifier.\n",
    "\"\"\"\n",
    "\n",
    "__maintainer__ = []\n",
    "__all__ = [\"RocketClassifier\"]\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from aeon.base._base import _clone_estimator\n",
    "from aeon.classification import BaseClassifier\n",
    "from aeon.transformations.collection.convolution_based import (\n",
    "    MiniRocket,\n",
    "    MultiRocket,\n",
    "    Rocket,\n",
    ")\n",
    "\n",
    "\n",
    "class RocketClassifier(BaseClassifier):\n",
    "    \"\"\"\n",
    "    Classifier wrapped for the Rocket transformer using RidgeClassifierCV.\n",
    "\n",
    "    This classifier simply transforms the input data using a Rocket [1,2,3]_\n",
    "    transformer, performs a Standard scaling and fits a sklearn classifier,\n",
    "    using the transformed data (default classifier is RidgeClassifierCV).\n",
    "\n",
    "    The classifier can be configured to use Rocket [1]_, MiniRocket [2]_ or\n",
    "    MultiRocket [3]_.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_kernels : int, default=10,000\n",
    "        The number of kernels for the Rocket transform.\n",
    "    rocket_transform : str, default=\"rocket\"\n",
    "        The type of Rocket transformer to use.\n",
    "        Valid inputs = [\"rocket\", \"minirocket\", \"multirocket\"].\n",
    "    max_dilations_per_kernel : int, default=32\n",
    "        MiniRocket and MultiRocket only. The maximum number of dilations per kernel.\n",
    "    n_features_per_kernel : int, default=4\n",
    "        MultiRocket only. The number of features per kernel.\n",
    "    estimator : sklearn compatible classifier or None, default=None\n",
    "        The estimator used. If None, a RidgeClassifierCV(alphas=np.logspace(-3, 3, 10))\n",
    "        is used.\n",
    "    class_weight{“balanced”, “balanced_subsample”}, dict or list of dicts, default=None\n",
    "        Only applies if estimator is None and the default is used.\n",
    "        From sklearn documentation:\n",
    "        If not given, all classes are supposed to have weight one.\n",
    "        The “balanced” mode uses the values of y to automatically adjust weights\n",
    "        inversely proportional to class frequencies in the input data as\n",
    "        n_samples / (n_classes * np.bincount(y))\n",
    "        The “balanced_subsample” mode is the same as “balanced” except that weights\n",
    "        are computed based on the bootstrap sample for every tree grown.\n",
    "        For multi-output, the weights of each column of y will be multiplied.\n",
    "        Note that these weights will be multiplied with sample_weight (passed through\n",
    "        the fit method) if sample_weight is specified.\n",
    "    n_jobs : int, default=1\n",
    "        The number of jobs to run in parallel for both `fit` and `predict`.\n",
    "        ``-1`` means using all processors.\n",
    "    random_state : int, RandomState instance or None, default=None\n",
    "        If `int`, random_state is the seed used by the random number generator;\n",
    "        If `RandomState` instance, random_state is the random number generator;\n",
    "        If `None`, the random number generator is the `RandomState` instance used\n",
    "        by `np.random`.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    n_classes_ : int\n",
    "        The number of classes.\n",
    "    classes_ : list\n",
    "        The classes labels.\n",
    "\n",
    "    See Also\n",
    "    --------\n",
    "    Rocket\n",
    "        Rocket transformers are in transformations/collection.\n",
    "    RocketRegressor\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] Dempster, A., Petitjean, F. and Webb, G.I., 2020. ROCKET: exceptionally fast\n",
    "        and accurate time series classification using random convolutional kernels.\n",
    "        Data Mining and Knowledge Discovery, 34(5), pp.1454-1495.\n",
    "    .. [2] Dempster, A., Schmidt, D.F. and Webb, G.I., 2021, August. Minirocket: A very\n",
    "        fast (almost) deterministic transform for time series classification. In\n",
    "        Proceedings of the 27th ACM SIGKDD conference on knowledge discovery & data\n",
    "        mining (pp. 248-257).\n",
    "    .. [3] Tan, C.W., Dempster, A., Bergmeir, C. and Webb, G.I., 2022. MultiRocket:\n",
    "        multiple pooling operators and transformations for fast and effective time\n",
    "        series classification. Data Mining and Knowledge Discovery, 36(5), pp.1623-1646.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from aeon.classification.convolution_based import RocketClassifier\n",
    "    >>> from aeon.datasets import load_unit_test\n",
    "    >>> X_train, y_train = load_unit_test(split=\"train\")\n",
    "    >>> X_test, y_test = load_unit_test(split=\"test\")\n",
    "    >>> clf = RocketClassifier(num_kernels=500)\n",
    "    >>> clf.fit(X_train, y_train)\n",
    "    RocketClassifier(...)\n",
    "    >>> y_pred = clf.predict(X_test)\n",
    "    \"\"\"\n",
    "\n",
    "    _tags = {\n",
    "        \"capability:multithreading\": True,\n",
    "        \"capability:multivariate\": True,\n",
    "        \"algorithm_type\": \"convolution\",\n",
    "    }\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_kernels=20000,\n",
    "        rocket_transform=\"rocket\",\n",
    "        max_dilations_per_kernel=32,\n",
    "        n_features_per_kernel=4,\n",
    "        estimator=None,\n",
    "        class_weight=None,\n",
    "        n_jobs=1,\n",
    "        random_state=None,\n",
    "    ):\n",
    "        self.num_kernels = num_kernels\n",
    "        self.rocket_transform = rocket_transform\n",
    "        self.max_dilations_per_kernel = max_dilations_per_kernel\n",
    "        self.n_features_per_kernel = n_features_per_kernel\n",
    "        self.estimator = estimator\n",
    "\n",
    "        self.class_weight = class_weight\n",
    "        self.n_jobs = n_jobs\n",
    "        self.random_state = random_state\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "    def _fit(self, X, y):\n",
    "        \"\"\"Fit Rocket variant to training data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 3D np.ndarray\n",
    "            The training data of shape = (n_cases, n_channels, n_timepoints).\n",
    "        y : 3D np.ndarray\n",
    "            The class labels, shape = (n_cases,).\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self :\n",
    "            Reference to self.\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        Changes state by creating a fitted model that updates attributes\n",
    "        ending in \"_\" and sets is_fitted flag to True.\n",
    "        \"\"\"\n",
    "        self.n_cases_, self.n_channels_, self.n_timepoints_ = X.shape\n",
    "\n",
    "        rocket_transform = self.rocket_transform.lower()\n",
    "        if rocket_transform == \"rocket\":\n",
    "            self._transformer = Rocket(\n",
    "                num_kernels=self.num_kernels,\n",
    "                n_jobs=self.n_jobs,\n",
    "                random_state=self.random_state,\n",
    "            )\n",
    "        elif rocket_transform == \"minirocket\":\n",
    "            self._transformer = MiniRocket(\n",
    "                num_kernels=self.num_kernels,\n",
    "                max_dilations_per_kernel=self.max_dilations_per_kernel,\n",
    "                n_jobs=self.n_jobs,\n",
    "                random_state=self.random_state,\n",
    "            )\n",
    "        elif rocket_transform == \"multirocket\":\n",
    "            self._transformer = MultiRocket(\n",
    "                num_kernels=self.num_kernels,\n",
    "                max_dilations_per_kernel=self.max_dilations_per_kernel,\n",
    "                n_features_per_kernel=self.n_features_per_kernel,\n",
    "                n_jobs=self.n_jobs,\n",
    "                random_state=self.random_state,\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid Rocket transformer: {self.rocket_transform}\")\n",
    "\n",
    "        self._scaler = StandardScaler(with_mean=False)\n",
    "        self._estimator = _clone_estimator(\n",
    "            (\n",
    "                RidgeClassifierCV(\n",
    "                    alphas=np.logspace(-3, 3, 10), class_weight=self.class_weight\n",
    "                )\n",
    "                if self.estimator is None\n",
    "                else self.estimator\n",
    "            ),\n",
    "            self.random_state,\n",
    "        )\n",
    "\n",
    "        self.pipeline_ = make_pipeline(\n",
    "            self._transformer,\n",
    "            self._scaler,\n",
    "            self._estimator,\n",
    "        )\n",
    "        self.pipeline_.fit(X, y)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def _predict(self, X) -> np.ndarray:\n",
    "        \"\"\"Predicts labels for sequences in X.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 3D np.ndarray of shape = (n_cases, n_channels, n_timepoints)\n",
    "            The data to make predictions for.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        y : array-like, shape = (n_cases,)\n",
    "            Predicted class labels.\n",
    "        \"\"\"\n",
    "        return self.pipeline_.predict(X)\n",
    "\n",
    "    def _predict_proba(self, X) -> np.ndarray:\n",
    "        \"\"\"Predicts labels probabilities for sequences in X.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 3D np.ndarray of shape = (n_cases, n_channels, n_timepoints)\n",
    "            The data to make predict probabilities for.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        y : array-like, shape = (n_cases, n_classes_)\n",
    "            Predicted probabilities using the ordering in classes_.\n",
    "        \"\"\"\n",
    "        m = getattr(self._estimator, \"predict_proba\", None)\n",
    "        if callable(m):\n",
    "            return self.pipeline_.predict_proba(X)\n",
    "        else:\n",
    "            dists = np.zeros((X.shape[0], self.n_classes_))\n",
    "            preds = self.pipeline_.predict(X)\n",
    "            for i in range(0, X.shape[0]):\n",
    "                dists[i, np.where(self.classes_ == preds[i])] = 1\n",
    "            return dists\n",
    "\n",
    "    @classmethod\n",
    "    def get_test_params(cls, parameter_set=\"default\"):\n",
    "        \"\"\"Return testing parameter settings for the estimator.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        parameter_set : str, default=\"default\"\n",
    "            Name of the set of test parameters to return, for use in tests. If no\n",
    "            special parameters are defined for a value, will return `\"default\"` set.\n",
    "            RocketClassifier provides the following special sets:\n",
    "                 \"results_comparison\" - used in some classifiers to compare against\n",
    "                    previously generated results where the default set of parameters\n",
    "                    cannot produce suitable probability estimates\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        params : dict or list of dict, default={}\n",
    "            Parameters to create testing instances of the class.\n",
    "            Each dict are parameters to construct an \"interesting\" test instance, i.e.,\n",
    "            `MyClass(**params)` or `MyClass(**params[i])` creates a valid test instance.\n",
    "            `create_test_instance` uses the first (or only) dictionary in `params`.\n",
    "        \"\"\"\n",
    "        if parameter_set == \"results_comparison\":\n",
    "            return {\"num_kernels\": 100}\n",
    "        else:\n",
    "            return {\"num_kernels\": 20}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 173737,
     "status": "ok",
     "timestamp": 1724485826929,
     "user": {
      "displayName": "Bijoyashree Das",
      "userId": "11723202937662517391"
     },
     "user_tz": -330
    },
    "id": "0dmQSVsBg39H",
    "outputId": "caf40d1c-ee21-44c3-a28f-899e5801dd24"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\WORKSTATIONS\\anaconda3\\envs\\endbd21\\Lib\\site-packages\\aeon\\base\\__init__.py:24: FutureWarning: The aeon package will soon be releasing v1.0.0 with the removal of legacy modules and interfaces such as BaseTransformer and BaseForecaster. This will contain breaking changes. See aeon-toolkit.org for more information. Set aeon.AEON_DEPRECATION_WARNING or the AEON_DEPRECATION_WARNING environmental variable to 'False' to disable this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\"\"\"MultiRocket classifier.\n",
    "\n",
    "Pipeline classifier using the MultiRocket transformer and RidgeClassifierCV classifier.\n",
    "\"\"\"\n",
    "\n",
    "__maintainer__ = [\"MatthewMiddlehurst\"]\n",
    "__all__ = [\"MultiRocketClassifier\"]\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from aeon.base._base import _clone_estimator\n",
    "from aeon.classification import BaseClassifier\n",
    "from aeon.transformations.collection.convolution_based import MultiRocket\n",
    "\n",
    "\n",
    "class MultiRocketClassifier(BaseClassifier):\n",
    "    \"\"\"\n",
    "    MultiRocket transformer using RidgeClassifierCV.\n",
    "\n",
    "    This classifier transforms the input data using the MultiRocket [1]_ transformer\n",
    "    extracting features from randomly generated kernels, performs a Standard scaling\n",
    "    and fits a sklearn classifier using the transformed data (default classifier is\n",
    "    RidgeClassifierCV).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_kernels : int, default=10,000\n",
    "        The number of kernels for the Rocket transform.\n",
    "    max_dilations_per_kernel : int, default=32\n",
    "        The maximum number of dilations per kernel.\n",
    "    n_features_per_kernel : int, default=4\n",
    "        The number of features per kernel.\n",
    "    estimator : sklearn compatible classifier or None, default=None\n",
    "        The estimator used. If None, a RidgeClassifierCV(alphas=np.logspace(-3, 3, 10))\n",
    "        is used.\n",
    "    class_weight{“balanced”, “balanced_subsample”}, dict or list of dicts, default=None\n",
    "        Only applies if estimator is None and the default is used.\n",
    "        From sklearn documentation:\n",
    "        If not given, all classes are supposed to have weight one.\n",
    "        The “balanced” mode uses the values of y to automatically adjust weights\n",
    "        inversely proportional to class frequencies in the input data as\n",
    "        n_samples / (n_classes * np.bincount(y))\n",
    "        The “balanced_subsample” mode is the same as “balanced” except that weights\n",
    "        are computed based on the bootstrap sample for every tree grown.\n",
    "        For multi-output, the weights of each column of y will be multiplied.\n",
    "        Note that these weights will be multiplied with sample_weight (passed through\n",
    "        the fit method) if sample_weight is specified.\n",
    "    n_jobs : int, default=1\n",
    "        The number of jobs to run in parallel for both `fit` and `predict`.\n",
    "        ``-1`` means using all processors.\n",
    "    random_state : int, RandomState instance or None, default=None\n",
    "        If `int`, random_state is the seed used by the random number generator;\n",
    "        If `RandomState` instance, random_state is the random number generator;\n",
    "        If `None`, the random number generator is the `RandomState` instance used\n",
    "        by `np.random`.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    n_classes_ : int\n",
    "        The number of classes.\n",
    "    classes_ : list\n",
    "        The classes labels.\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] Tan, C.W., Dempster, A., Bergmeir, C. and Webb, G.I., 2022. MultiRocket:\n",
    "        multiple pooling operators and transformations for fast and effective time\n",
    "        series classification. Data Mining and Knowledge Discovery, 36(5), pp.1623-1646.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from aeon.classification.convolution_based import MultiRocketClassifier\n",
    "    >>> from aeon.datasets import load_unit_test\n",
    "    >>> X_train, y_train = load_unit_test(split=\"train\")\n",
    "    >>> X_test, y_test = load_unit_test(split=\"test\")\n",
    "    >>> clf = MultiRocketClassifier(n_kernels=500)\n",
    "    >>> clf.fit(X_train, y_train)\n",
    "    MultiRocketClassifier(...)\n",
    "    >>> y_pred = clf.predict(X_test)\n",
    "    \"\"\"\n",
    "\n",
    "    _tags = {\n",
    "        \"capability:multithreading\": True,\n",
    "        \"capability:multivariate\": True,\n",
    "        \"algorithm_type\": \"convolution\",\n",
    "    }\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_kernels: int = 10000,\n",
    "        max_dilations_per_kernel: int = 32,\n",
    "        n_features_per_kernel: int = 4,\n",
    "        estimator=None,\n",
    "        class_weight=None,\n",
    "        n_jobs: int = 1,\n",
    "        random_state=None,\n",
    "    ):\n",
    "        self.n_kernels = n_kernels\n",
    "        self.max_dilations_per_kernel = max_dilations_per_kernel\n",
    "        self.n_features_per_kernel = n_features_per_kernel\n",
    "        self.estimator = estimator\n",
    "\n",
    "        self.class_weight = class_weight\n",
    "        self.n_jobs = n_jobs\n",
    "        self.random_state = random_state\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "    def _fit(self, X, y):\n",
    "        \"\"\"Fit Rocket variant to training data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 3D np.ndarray\n",
    "            The training data of shape = (n_cases, n_channels, n_timepoints).\n",
    "        y : 3D np.ndarray\n",
    "            The class labels, shape = (n_cases,).\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self :\n",
    "            Reference to self.\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        Changes state by creating a fitted model that updates attributes\n",
    "        ending in \"_\" and sets is_fitted flag to True.\n",
    "        \"\"\"\n",
    "        self.n_cases_, self.n_channels_, self.n_timepoints_ = X.shape\n",
    "\n",
    "        self._transformer = MultiRocket(\n",
    "            n_kernels=self.n_kernels,\n",
    "            max_dilations_per_kernel=self.max_dilations_per_kernel,\n",
    "            n_features_per_kernel=self.n_features_per_kernel,\n",
    "            n_jobs=self.n_jobs,\n",
    "            random_state=self.random_state,\n",
    "        )\n",
    "        self._scaler = StandardScaler(with_mean=False)\n",
    "        self._estimator = _clone_estimator(\n",
    "            (\n",
    "                RidgeClassifierCV(\n",
    "                    alphas=np.logspace(-3, 3, 10), class_weight=self.class_weight\n",
    "                )\n",
    "                if self.estimator is None\n",
    "                else self.estimator\n",
    "            ),\n",
    "            self.random_state,\n",
    "        )\n",
    "\n",
    "        self.pipeline_ = make_pipeline(\n",
    "            self._transformer,\n",
    "            self._scaler,\n",
    "            self._estimator,\n",
    "        )\n",
    "        self.pipeline_.fit(X, y)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def _predict(self, X) -> np.ndarray:\n",
    "        \"\"\"Predicts labels for sequences in X.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 3D np.ndarray of shape = (n_cases, n_channels, n_timepoints)\n",
    "            The data to make predictions for.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        y : array-like, shape = (n_cases,)\n",
    "            Predicted class labels.\n",
    "        \"\"\"\n",
    "        return self.pipeline_.predict(X)\n",
    "\n",
    "    def _predict_proba(self, X) -> np.ndarray:\n",
    "        \"\"\"Predicts labels probabilities for sequences in X.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 3D np.ndarray of shape = (n_cases, n_channels, n_timepoints)\n",
    "            The data to make predict probabilities for.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        y : array-like, shape = (n_cases, n_classes_)\n",
    "            Predicted probabilities using the ordering in classes_.\n",
    "        \"\"\"\n",
    "        m = getattr(self._estimator, \"predict_proba\", None)\n",
    "        if callable(m):\n",
    "            return self.pipeline_.predict_proba(X)\n",
    "        else:\n",
    "            dists = np.zeros((X.shape[0], self.n_classes_))\n",
    "            preds = self.pipeline_.predict(X)\n",
    "            for i in range(0, X.shape[0]):\n",
    "                dists[i, np.where(self.classes_ == preds[i])] = 1\n",
    "            return dists\n",
    "\n",
    "    @classmethod\n",
    "    def _get_test_params(cls, parameter_set=\"default\"):\n",
    "        \"\"\"Return testing parameter settings for the estimator.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        parameter_set : str, default=\"default\"\n",
    "            Name of the set of test parameters to return, for use in tests. If no\n",
    "            special parameters are defined for a value, will return `\"default\"` set.\n",
    "            RocketClassifier provides the following special sets:\n",
    "                 \"results_comparison\" - used in some classifiers to compare against\n",
    "                    previously generated results where the default set of parameters\n",
    "                    cannot produce suitable probability estimates\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        params : dict or list of dict, default={}\n",
    "            Parameters to create testing instances of the class.\n",
    "            Each dict are parameters to construct an \"interesting\" test instance, i.e.,\n",
    "            `MyClass(**params)` or `MyClass(**params[i])` creates a valid test instance.\n",
    "        \"\"\"\n",
    "        if parameter_set == \"results_comparison\":\n",
    "            return {\"n_kernels\": 100}\n",
    "        else:\n",
    "            return {\n",
    "                \"n_kernels\": 200,\n",
    "                \"max_dilations_per_kernel\": 8,\n",
    "                \"n_features_per_kernel\": 4,\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jqleLI-_g39L",
    "outputId": "0a9ce574-c0ec-44a8-895c-a0ffaf89dc15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of files in folder 'down': 2359\n",
      "Total number of files in folder 'go': 2372\n",
      "Total number of files in folder 'left': 2353\n",
      "Total number of files in folder 'no': 2375\n",
      "Total number of files in folder 'off': 2357\n",
      "Total number of files in folder 'on': 2367\n",
      "Total number of files in folder 'right': 2367\n",
      "Total number of files in folder 'silence': 2010\n",
      "Total number of files in folder 'stop': 2380\n",
      "Total number of files in folder 'unknown': 2000\n",
      "Total number of files in folder 'up': 2375\n",
      "Total number of files in folder 'yes': 2377\n",
      "(27692, 1, 16000)\n",
      "(27692,)\n",
      "[ 0  0  0 ... 11 11 11]\n",
      "Overall total number of files in the dataset: 27692\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "\n",
    "def load_data_from_directory(directory, sample_length=16000, n_channels=1):\n",
    "    X = []\n",
    "    y = []\n",
    "    labels = sorted(os.listdir(directory))\n",
    "    label_map = {label: idx for idx, label in enumerate(labels)}  # Create a label to index mapping\n",
    "\n",
    "    total_files = 0  # Initialize a counter for total files\n",
    "\n",
    "    for label in labels:\n",
    "        class_dir = os.path.join(directory, label)\n",
    "        if os.path.isdir(class_dir):\n",
    "            file_count = 0  # Counter for files in the current class directory\n",
    "            for file_name in os.listdir(class_dir):\n",
    "                if file_name.endswith('.wav'):\n",
    "                    file_count += 1  # Increment file count for the current class\n",
    "                    file_path = os.path.join(class_dir, file_name)\n",
    "                    # Load audio\n",
    "                    signal, sr = librosa.load(file_path, sr=16000)\n",
    "                    # Ensure length is 1 second (16000 samples)\n",
    "                    if len(signal) != sample_length:\n",
    "                        # Pad or truncate to sample_length\n",
    "                        if len(signal) < sample_length:\n",
    "                            signal = np.pad(signal, (0, sample_length - len(signal)))\n",
    "                        else:\n",
    "                            signal = signal[:sample_length]\n",
    "                    # Reshape signal to match (n_channels, n_timepoints)\n",
    "                    X.append(signal.reshape(n_channels, -1))  # Reshape to (1, sample_length)\n",
    "                    y.append(label_map[label])  # Use the index of the label\n",
    "\n",
    "            total_files += file_count  # Add the current class file count to the total\n",
    "            print(f\"Total number of files in folder '{label}': {file_count}\")\n",
    "\n",
    "    # Convert lists to numpy arrays\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    print(X.shape)\n",
    "    print(y.shape)\n",
    "    print(y)\n",
    "    print(f\"Overall total number of files in the dataset: {total_files}\")\n",
    "\n",
    "    return X, y, labels\n",
    "\n",
    "# Load and preprocess data\n",
    "directory = \"C:/Users/WORKSTATIONS/Desktop/BijoyashreeDas/12KWS\"\n",
    "X, y, labels = load_data_from_directory(directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Lc6AZsymg39M"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Q5btkexOg39M"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Split data into training and testing sets with a fixed random_state\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Classifier\n",
    "\n",
    "clf = RocketClassifier(\n",
    "    random_state=SEED,num_kernels=120000\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the classifier on the training data\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "11pB32yMg39N"
   },
   "outputs": [],
   "source": [
    "# Predict on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Print the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy on test data:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Calculate precision, recall, and f1 score for each class (macro average)\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "print(f\"Precision (macro): {precision}\")\n",
    "print(f\"Recall (macro): {recall}\")\n",
    "print(f\"F1 Score (macro): {f1}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_curve, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "\n",
    "# Plot confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
